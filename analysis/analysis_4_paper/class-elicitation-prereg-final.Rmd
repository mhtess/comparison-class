---
title: "Comparison Class Elicitation Experiment "
author: "MH Tessler"
date: "October 29, 2019"
---

The comparison class elicitation experiment is a free prduction experiment where participants read a context sentence about a target object (NP) and paraphrase an utterance involving a gradable adjective by providing an explicit comparison class for the gradable adjective; we analyse the produced comparison classes and categorize them into "subordinate" and "superordinate" comparison classes.

# Analysis Outline

First, the raw responses are processed automatically by matching responses to keywords providing the essence of the respective comparison class: mostly, we match against the NPs of the sentence (referent NPs) and the anticipated superordinate of the item. In order to improve the automatic classification we lemmatize and correct for misspellings of the raw responses. 

Second, the responses which were not processed automatically are processed manually. From these responses, we looked for responses thatwere produced by at least three participants and noted these as consistent comparison classes that were different from the referent NP and the anticiapted superordinate. 

The analysis proceedes from simplest processing steps to more sophisticated processing steps, leading to the output of dataframes containing data passing these different processing steps. 

At the end, data visualisations and regression models can be found.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Load libraries.
library(knitr)
library(tidyverse)
library(tidyboot)
library(tidytext)
library(lme4)
library(ggthemes)
library(brms)
library(stringr)
theme_set(theme_few())


```

## Load data

```{r load data from csv, warnings=F}
df.trials <- read_csv("../../data/class-elicitation-prereg-final/class-elicitation-prereg-final-trials.csv")
df.subject <- read_csv("../../data/class-elicitation-prereg-final/class-elicitation-prereg-final-subject_information.csv")
df.attention <- read_csv("../../data/class-elicitation-prereg-final/class-elicitation-prereg-final-catch_trials.csv")
```

## Participant Exclusion 

Before the main trials, participants completed warm-up trials testing task comprehension (an easy paraphrase task of the kind appearing in the main trials). 

```{r comprehension check}
df.botcaptcha <- df.attention %>%
  filter(condition == "botcaptcha")

df.comprehension <- df.attention %>%
  filter(condition == "warm_up") %>%
  rowwise() %>%
  mutate(pass_comp = (
    containsString(tolower(response), "build") |
      containsString(tolower(response), "bulid") |
      containsString(tolower(response), "buid") |
      containsString(tolower(response), "skyscraper") |
      containsString(tolower(response), "skyscaper") |
      containsString(tolower(response), "structure") |
      containsString(tolower(response), "bulding") |
      containsString(tolower(response), "builing") |
      containsString(tolower(response), "bildin") |
      containsString(tolower(response), "towe")
  ))

df.comprehension %>% 
  group_by(pass_comp) %>%
  count() %>%
  kable()

# What did people write-in that was incorrect?
df.comprehension %>% 
  filter(!pass_comp) %>%
  View()
```

After the main trials, they completed a memory check trial asking which adjective-NP combinations appeared on the main trials. Participants are excluded if they answer less than 7 out of 10 memory check questions correctly or if they respond incorrectly on the warm-up trials.

```{r memory check}
df.memory <- df.attention %>%
  filter(condition == "memory_check") %>%
  group_by(workerid) %>%
  summarize(
    n_correct = sum(correct),
    pass_memory = n_correct >= 7
  )

df.memory %>%
  group_by(n_correct) %>%
  count() %>%
  kable()

df.memory %>%
  group_by(pass_memory) %>%
  count() %>%
  kable()
```



```{r summarize catch trials}
df.attention.summary <- left_join(
  df.comprehension %>% select(workerid, pass_comp),
  df.memory %>% select(workerid, pass_memory)
) %>%
  mutate(pass_both = pass_comp & pass_memory)


df.attention.summary %>%
  group_by(pass_comp, pass_memory, pass_both) %>%
  count()
```

```{r apply exclusion critera}
df.trials.filtered <- df.trials %>%
  left_join(., df.attention.summary) %>%
  filter(pass_both)

n.total.responses <- df.trials.filtered %>%
  ungroup() %>%
  count() %>%
  pull(n)

paste("total number of responses =", n.total.responses)
```

```{r item counts}
d.item.count <- df.trials.filtered %>%
  group_by(stim_id, np_expectations, adj_polarity) %>%
  count()

d.item.count %>%
  ungroup() %>%
  group_by(n) %>%
  count() %>%
  ggplot(., aes(x = n, y = nn)) +
  geom_col() +
  xlab("n responses per item") +
  ylab("n items")
```

# Text preprocessing

## Exclusions

### Nonsense

We exclude nonsense responses: These are the responses the are just the name of the speaker, just the adjective, an adjectival sentence without a comparison class or non-sense words. These invalid responses were extracted manually.

```{r list of invalid responses}
invalid.responses <- c(
  "unsure",
  # all the adjectives
  "long", "short", "tall", "dark", "light", "fast", "quick", "slow",
  "hard", "soft", "loud", "noisy", "quiet", "bright", "bruises",
  "expensive", "cheap", "big", "small", "strong", "weak", "warm", "hot", "cold",
  "heavy", "wide", "narrow",
  # all the actor names
  "alexander", "alicia", "cheep", "daniel", "darker",
  "david",
  "eric", "gabriel", "anthony", "william", "john", "tom", "lucas",
  "michael", "cameron", "stephen",
  "lee", "greg", "robert", "chrales", "gary", "josh", "simon",
  "angela", "jennifer", "monica", "melinda", "veronica", "alicia",
  "maya", "sophie", "kim", "laura", "julia",
  "michelle", "stephanie", "claire", "kathleen", "jasmine", "tanya",
  "mika", "natalia",
  # invalid responses
  "barbell snatch", "bank of america", "easy", "empire building", "chill", "chinn", "webside",
  "finished", "flexibility", "health", "hot cold",
  "lazy", "low", "cliaire", "feelings", "too small", "Too small",
  "public", "ripe", "silent", "baked", "burn", "more costly", "exacting",
  # filter out the sentences without a CC
  "A bottle of wine at a liquor store was expensive", "A piece of cotton in craft shop was light", "A piece of plastic in hardware store was soft",
  "A spider in an insect terrarium was big", "At the butchershop the chicken was expensive", "At the conference center it was noisy when she met her friend", "during the night its light out there",
  "hears the cry of a crow", "In Aquarium a tuna was big", "In botanical garden an alpine tree was short.", "In summer that day was cold", "In the freezer michelle hand was cold", "it has a lot of stuff",
  "It was noisy in the nearby city", "its not a hot and cold", "move furniture through the front gate of her house", "picks up a piece of silk.", "the coat is light in weight", "	The coat of poodle was dark",
  "the color of the script is light", "the daisy is dark in color", "The first bite of her ice cream was warm", "The first sip of juice was cold", "The furniture was narrow at the back door of his house", "The new place rental rate is expensive", "the pair of sandals are expensive", "	The piece of silk is light.",
  "the sound of the shower is strong", "The statue made of plastic was cheap", "the walls of the condo are strong", "While walking heard the cry of a rooster when it was quiet", "Basketball player was tall",
  "Friend's new rowboat was fast", "Friend's new smartcar is big", "his favorite poem was short", "it is not destructive", "it is not loud", "it is not sold expensively", "it s not wide", "its noisy in here",
  "its not a soft", "On Saturday it was cold", "STRIP MALL IS SHORT", "summer days are warm", "That baby was loud", "the adult walk quickly", "The airplane is slow.", "The bird is loud.", "the car drives by quietly", "the car is quite", "the child is not fussy", "The child walks slow.", "The coat of poodle was dark", "large", "lengthy", "Little",
  "the color is not much", "the day is cold", "the dog's body is long", "The environment is quiet.", "the floor is soft", "The flower is short.", "the food is expensive", "the fruit cake was light", "the information is  long", "The mall is short.", "The mattress s firm", "the melon was soft", "the mouse is small", "the pages are not many", "the pencil color is light", "The piece of silk is light.", "The country lane was narrow", "The new place rental rate is expensive.", "The poodle's coat is light.", "the powerboat makes no noise", "the rabbit is fast", "the sneakers are costly", "the statue is cheap", "the street is wide", "The weather is cold today.", "The suit was expensive", "The trash is light.", "The watermelon was light", "A rock concert was loud", "little",
  "the movie i hope", "all light of off", "sits on a blanket", "try a new water color",
  "driving on a downtown street", "The spider was small", "The music was Loud",
  "powerboat sound little quiet", "Horn was too loud", "Villa price was costly",
  "choral consert was too loud", "milkshake was so hot", "strip mall was tall",
  "plastic was so soft", "pork was too expensive", "price of raspberries expensive",
  "coat of a spaniel was little light", "village area was too quit to read",
  "elderly person was too quick", "conference room was too quiet", "instant pot was slow",
  "tile floor was soft", "chocolate cake color was too dark", "marshmallow was soft for eat",
  "Blue paint is dark", "pick-ip truck was long", "sits on a bedboard.", "tails on mice",
  "they are bold", "the blade spinning", "its finished", "not sure", "too slow",
  "black", "boiling", "coat of paints", "Empire State Building", "glare", "indvidual experience", "information", "It is not loud", "It was night", "It was strong", "itrs warm", "its hot", "its low", "its low cost", "its not hard", "its not mute", "its not slow", "its not soft", "its not speed", "its too sound", "its wide", "lengthy", "less wide", "melting", "More costly", "move", "muscles", "pcks", "Relationship", "sexy", "Silent", "the duration", "the distance", "the have muscles", "they are fit", "they run fast", "thrill", "though", "Very slow", "walking outside", "walking assistance tools", "word", "worthy", "tough", "picks up their trash can.", "all lights off", "amount", "high", "its long", "it cooks quickly", "little", "outside"
)
```

Simple (invalid) copular sentences including no comparison classes are constructed and excluded together with the invalid responses above.

``` {r excludeInvalidResps}
# excluding invalid responses
d.tidy.resps.catch <- df.trials.filtered %>%
  filter((grepl("it's", response, ignore.case = T) |
    grepl("they're", response, ignore.case = T)))

# get invalid responses which are full sentences without any comparison class
d.tidy.resp.valid <- anti_join(
  df.trials.filtered,
  d.tidy.resps.catch
) %>%
  rowwise() %>%
  mutate(
    stopPhrase = paste("the", np, "is", adj, sep = " "),
    stopPhrase2 = paste("the", np, "is",
      paste(adj, ".", sep = ""),
      sep = " "
    ),
    responseLength = lengths(str_split(response, " "))
  ) %>%
  filter((tolower(response) != stopPhrase) &
    (tolower(response) != stopPhrase2))

# get the long responses that were not matched above and filter them out manually
# d.tidy.resp.valid.resps %>% filter(responseLength >= 4) %>% View()

d.tidy.resp.valid <- d.tidy.resp.valid %>%
  rowwise() %>%
  # exclude responses which excatly match the ones in the following list
  subset(., !(response %in% invalid.responses))

n.valid.responses <- d.tidy.resp.valid %>%
  ungroup() %>%
  count() %>%
  pull(n)

n.total.responses - n.valid.responses
(n.total.responses - n.valid.responses) / n.total.responses
```


### Reference failure

Some responses fail to establish correct reference, e.g. participants referred to the wrong entity mentioned in the context sentence: given the sentence "John sees an adult lift a box" and the comment "John says: 'They're strong'", when asked who the adult is strong relative to, some subjects responded "relative to other boxes". Since these 'failed-reference' responses often mention distractor nouns in the context sentence, we extract these responses by looking for specific words from the contexts. 

``` {r}
# remove responses failig to establish correct reference 
d.tidy.resp.valid.FailedRef <- d.tidy.resp.valid %>%
  mutate(response = tolower(response)) %>%
  rowwise() %>%
  mutate(failed_ref = FALSE,
         failed_ref = ifelse(grepl("aquarium", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("bank", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("box", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("butchershops", response, fixed = T), TRUE,
                             failed_ref),
         failed_ref = ifelse(grepl("butcher shops", response, fixed = T), TRUE,
                             failed_ref),
         failed_ref = ifelse(grepl("butchershops' chickens", response, fixed = T),
                             FALSE, failed_ref),
         failed_ref = ifelse(grepl("bank", response, fixed = T), TRUE, failed_ref),
         failed_ref = ifelse(grepl("banks", response, fixed = T), TRUE, failed_ref),
         failed_ref = ifelse(grepl("creek banks", response, fixed = T), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("river banks", response, fixed = T), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("stream banks", response, fixed = T), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("forest", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("pieces of furniture", response), TRUE,
                             failed_ref),
         failed_ref = ifelse(grepl("sounds in the forest", response), TRUE,
                             failed_ref),
         failed_ref = ifelse((grepl("furniture", response) & (stim_id == 90)),
                             TRUE, failed_ref),
         failed_ref = ifelse((grepl("night", response)& (stim_id == 32)),
                             TRUE, failed_ref),
         failed_ref = ifelse(grepl("saturday", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("terrarium", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("google maps", response), TRUE, failed_ref),
         failed_ref = ifelse((grepl("highway", response) & (stim_id == 62)),
                             TRUE, failed_ref),
         failed_ref = ifelse(grepl("kitchen", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("items in the kitchen", response), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("kitchen appliances", response), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("kitchen cooking appliances", response), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("kitchenware", response), FALSE, failed_ref),
         failed_ref = ifelse(grepl("lake", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("map", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("park", response), TRUE, failed_ref),
         failed_ref = ifelse(grepl("sound", response), FALSE, failed_ref),
         failed_ref = ifelse((grepl("weight", response)& (stim_id == 69)), TRUE,
                             failed_ref),
         failed_ref = ifelse(grepl("weight lifters", response), FALSE,
                             failed_ref),
         failed_ref = ifelse(grepl("weightlifters", response), FALSE,
                             failed_ref),
  ) %>% filter((responseLength < 3) & # longer responses contain the target N
               (failed_ref == TRUE) & 
               (response != "pieces of furniture")
               )
```

``` {r}
# remove reference failure
d.tidy.resp.valid.noFailedRef <- anti_join(
  d.tidy.resp.valid,
  d.tidy.resp.valid.FailedRef,
  by = c("stim_id", "response")    ) 
```


## Corrections: Misspellings, Lemmatization, Synonyms

### Misspelling Correction

In order to improve matching of the provided repsonses to the subordinate NPs or the anticipated superordinate labels, we correct misspellings occurring in the provided responses. The misspellings were extracted manually. The misspellings and corrections are read from the dataframe and converted to a named list which is used with str_replace_all. 

```{r list of commong mispellings}
misspellings_df <- read_csv("text_processing/misspellings_dict.csv") 

misspellings_set <- pull(misspellings_df, V2) %>% set_names(pull(misspellings_df, V1))
```


### Lemmatization 

To further improve the response classification, we lemmatize the plural responses (specifically, the irregular nouns and misspellings) to match the NPs and superordinates (e.g. 'libraries' is converted to 'library').

```{r list of lemmatizations}
# mostly Plural --> singulars
lemmatization_df <- read_csv("text_processing/lemmatization_dict.csv") %>%
  rowwise() %>%
  mutate(
    V2 = ifelse(is.na(V2), "",
      V2
    )
  )
lemmatization_set <- pull(lemmatization_df, V2) %>% set_names(pull(lemmatization_df, V1))
```

### Synonym Extraction

To further improve the response classification, we also replace some raw responses which are obviously synonymous to the provided subordinate or superoridnate NPs given the context (e.g. 'automobile' is converted to 'car') .
```{r list of common synonyms}
synonym_df <- read_csv("text_processing/synonym_dict.csv")
synonym_set <- pull(synonym_df, V2) %>% set_names(pull(synonym_df, V1))
```



```{r apply corrections}
d.tidy.resp.valid.noFailedRef %>%
  mutate(response = as.character(response)) %>%
  ungroup() %>%
  mutate(
    response_spelling = str_replace_all(tolower(response), misspellings_set),
    response_synonym = str_replace_all(response_spelling, synonym_set),
    # ITEM-SPECIFIC SYNONYMS
    response_synonym = case_when(
        (stim_id == 25 && response_synonym == "episode") ~ "sitcom",
        (stim_id == 28 && response_synonym == "episode") ~ "podcast episode",
        (stim_id == 29 && response_synonym == "rock") ~ "rock concert",
        (stim_id == 81 && response_synonym == "cans") ~ "trash can",
        TRUE ~ response_synonym
      ),
    response_lemma = tolower(str_replace_all(response_synonym, lemmatization_set))
  ) %>%
  mutate(
    corrected_spelling = response != response_spelling,
    corrected_synonym = response_spelling != response_synonym,
    corrected_lemma = response_synonym != response_lemma
  ) -> d.tidy.resp.valid.lemmatized


sum(d.tidy.resp.valid.lemmatized$corrected_spelling)
sum(d.tidy.resp.valid.lemmatized$corrected_spelling) / n.valid.responses
sum(d.tidy.resp.valid.lemmatized$corrected_synonym)
sum(d.tidy.resp.valid.lemmatized$corrected_synonym) / n.valid.responses
sum(d.tidy.resp.valid.lemmatized$corrected_lemma)
sum(d.tidy.resp.valid.lemmatized$corrected_lemma) / n.valid.responses
```



testing out item-specific replacements
```{r}
# d.tidy.resp.valid %>% filter(response %in% c("episode", "episodes")) %>% View()
# d.tidy.resp.valid %>% filter(response %in% c("weather")) %>% View()
```



## Match keyword(s) in Responses

For automated checking of whether or not responses contain the supplied NP (i.e. are subordinate) or the anticipated superordinate of the item (i.e. are superordinate), we distill multi-word NPs (e.g., "six-pack of beer") to single words (e.g., "beer") that we think convey the essence of the subordinate category given the context. And so, if we see a response containing the word "beer", then it will be marked as *specific* (i.e., including the mentioned NP). 

```{r np match}
d.tidy.resp.valid.lemmatized.np_match <- d.tidy.resp.valid.lemmatized %>%
  rowwise() %>%
  mutate(
    np_match = tolower(np), # additional column where we put the NP to be matched against, such that the original NPs can be accessed if necessary
    np_match = gsub("bottle of top-shelf liquor", "liquor", np_match),
    np_match = gsub("piece of chocolate", "chocolate", np_match),
    np_match = gsub("piece of chalk", "chalk", np_match),
    np_match = gsub("six-pack of beer", "beer", np_match),
    np_match = gsub("bottle of wine", "wine", np_match),
    np_match = gsub("pine tree", "pine", np_match),
    np_match = gsub("redwood tree", "redwood", np_match),
    np_match = gsub("alpine tree", "alpine", np_match),
    np_match = gsub("bonsai tree", "bonsai", np_match),
    np_match = gsub("pick-up truck", "pick-up", np_match),
    np_match = gsub("relay race", "relay", np_match),
    np_match = gsub("triathlon race", "triathlon", np_match),
    np_match = gsub("sprinting race", "sprint", np_match),
    np_match = gsub("kettle ball", "ball", np_match),
    np_match = gsub("study hall", "study", np_match),
    np_match = gsub("electric car", "electric", np_match),
    np_match = gsub("bass guitar", "bass", np_match),
    np_match = gsub("choral concert", "choral", np_match),
    np_match = gsub("rap concert", "rap", np_match),
    np_match = gsub("white paint", "white", np_match),
    np_match = gsub("blue paint", "blue", np_match),
    np_match = gsub("black paint", "black", np_match),
    np_match = gsub("limousine", "limo", np_match),
    np_match = gsub("smartcar", "smart", np_match),
    np_match = gsub("japanese restaurant", "japanese", np_match),
    np_match = gsub("chinese restaurant", "chinese", np_match),
    np_match = gsub("korean restaurant", "korean", np_match),
    np_match = gsub("elderly person", "elder", np_match),
    np_match = gsub("oil paint", "oil", np_match),
    np_match = gsub("wall paint", "wall", np_match),
    np_match = gsub("shopping mall", "mall", np_match),
    np_match = gsub("chocolate fondue", "fondue", np_match),
    np_match = gsub("cell phone", "phone", np_match),
    np_match = gsub("bear den", "bear", np_match),
    np_match = gsub("fox den", "fox", np_match),
    np_match = gsub("mouse den", "mouse", np_match),
    np_match = gsub("downtown street", "downtown", np_match),
    np_match = gsub("side road", "side", np_match),
    np_match = gsub("back door", "back", np_match),
    np_match = gsub("patio door", "patio", np_match),
    np_match = gsub("front gate", "front", np_match),
    np_match = gsub("chocolate cake", "chocolate", np_match),
    np_match = gsub("podcast episode", "podcast", np_match)#,
    #superordinate = ifelse(stim_id == 77, "food", superordinate)
  )
```



# Automatic Classification

The preprocessed responses are automatically classified into subordinate and superordinate by matching them against the preprocessed subordinate keywords and superordinates. We check if the response includes either the keyword or the superordinate and if either includes the response. Furthermore, since we check either way and some NPs are composites including the superordinate, we manually check if the response is just the superordinate ('berries') and classify it as the superordinate accordingly. 

```{r check if response contains sub/super and visa versa}
d.tidy.resp.valid.lemmatized.np_match %>%
  rowwise() %>%
  mutate(
    specific = grepl(np_match, response_lemma, fixed = TRUE),
    super_in_resp = grepl(superordinate, response_lemma, fixed = TRUE),
    resp_in_super = grepl(response_lemma, superordinate, fixed = TRUE),
    matchingSuper = ifelse(!specific, super_in_resp || resp_in_super, FALSE)
  ) -> d.tidy.auto

with(d.tidy.auto, table(specific, matchingSuper)) %>% 
  kable()

# d.tidy.auto %>% 
#   select(response, response_lemma_us, np_match,  specific, superordinate, super_in_resp, response_lemma, super_us, resp_in_super, matchingSuper) %>%
#   View()

# extract the automatically classified data
d.tidy.auto.match <- d.tidy.auto %>%
  filter(matchingSuper || specific)

n.automatic.responses <- d.tidy.auto.match %>%
  ungroup() %>%
  count() %>%
  pull(n)

n.automatic.responses
n.automatic.responses / n.valid.responses
```

Responses for items that were classified as all subordinate or superordinate (mean = 0 or 1) are double-checked.

```{r check ceiling/floor responses}
# check the matched items where the mean of responses is 1 or 0
d.tidy.auto.match %>%
  group_by(stim_id, np_expectations, adj_polarity) %>%
  mutate(meanResp = mean(specific)) %>%
  filter((meanResp == 1) | (meanResp == 0)) %>%
  distinct(
    stim_id, np_expectations,
    np_match, adj_polarity, adj,
    response_lemma, # showing response_lemma will show the individual (lemmatized) responses that were all categorized as either sub or super
    meanResp
  ) -> d.match.ceiling
  
d.match.ceiling %>%
  distinct(stim_id, np_expectations, adj_polarity, meanResp) %>%
  group_by(meanResp) %>%
  count()

d.match.ceiling %>%
  ungroup() %>%
  distinct(
    stim_id, np_expectations,  
    np_match, adj,
    meanResp
  ) %>%
  sample_n(20) %>%
  kable()
  #View()

d.match.ceiling %>%
  ungroup() %>%
  filter(meanResp == 1) %>%
  distinct(
    stim_id, np_expectations,  
    np_match, adj_polarity,
    meanResp
  ) %>%
  group_by(np_expectations, adj_polarity) %>%
  count() %>%
  ungroup() %>%
  mutate(np_expectations = factor(np_expectations, levels = c("low", "medium", "high"))) %>%
  rename(adjpol = adj_polarity) %>%
  spread(np_expectations, n) %>% 
  kable()
  # write_csv(., "../../writing/paper/csv_data_4_tex/itemCounts_ceil_floor.csv")
```

## Post-processing of Automatically Classified Data

After we manually inspected the data with respect to superordinate responses that systematically deviated from the anticipated ones, we modified one item (77 "desserts") for which the superordinate deviated (participants tended to paraphrase the more general class as "food"). We use the empirical modal superordinate ("food") for the frequency extraction and the adjective endorsement task. 
If the response was classified as subordinate (i.e. _specific_), it is turned into be the corresponding NP (represented by the variable `mode_np`), otherwise it is turned into the corresponding superordinate.

``` {r}
d.tidy.auto.match.adjust_super <- d.tidy.auto.match %>%
  mutate(
    # substitutions made based on human modal responses
    superordinate = ifelse(stim_id == 77, "food", superordinate)
  ) %>%
  # if the response is specific (subordinate), the modal NP is inserted, otherwise the modal superordinate is inserted
  mutate(mode_np = ifelse(specific == 1, np, superordinate))
```

### Frequencies

```{r plural np for freq}
# this function takes the raw NPs that we use in the experiment, e.g. 'six-pack of beer' (not the substituted key-words, e.g.,  beer, that we used for automatic categorization) to create the respective plural NPs we use for frequencies
insert_plural_np <- function(np, superordinate) {
  if (np %in% c("piece of chocolate")) {
    np_pl <- "chocolates"
  } else if (np %in% c("piece of chalk")) {
    np_pl <- "chalks"
  } else if (np %in% c("story")) {
    np_pl <- "stories"
  } else if (np %in% c("daisy")) {
    np_pl <- "daisies"
  } else if (np %in% c("library")) {
    np_pl <- "libraries"
  } else if (np %in% c("party")) {
    np_pl <- "parties"
  } else if (np %in% c("bush")) {
    np_pl <- "bushes"
  } else if (np %in% c("finch")) {
    np_pl <- "finches"
  } else if (np %in% c("pansy")) {
    np_pl <- "pansies"
  } else if (np %in% c("documentary")) {
    np_pl <- "documentaries"
  } else if (np %in% c("pantry")) {
    np_pl <- "pantries"
  } else if (np %in% c("choral concert")) {
    np_pl <- "choirs"
  } else if (np %in% c("elderly person")) {
    np_pl <- "elderly people"
  } else if (np %in% c("mouse")) {
    np_pl <- "mice"
  } else if (np %in% c("church")) {
    np_pl <- "churches"
  } else if (np %in% c("tile")) {
    np_pl <- "tile floors"
  } else if (np %in% c("wood") & (superordinate == "floors")) {
    np_pl <- "wood floors"
  } else if (np %in% c("carpet") & (superordinate == "floors")) {
    np_pl <- "carpet floors"
  } else if (np %in% c("summer")) {
    np_pl <- "summer days"
  } else if (np %in% c("fall")) {
    np_pl <- "fall days"
  } else if (np %in% c("winter")) {
    np_pl <- "winter days"
  } else if (np %in% c("couch")) {
    np_pl <- "couches"
  } else if (np %in% c("tomato")) {
    np_pl <- "tomatoes"
  } else if (np %in% c("jolly rancher")) {
    np_pl <- "jollies"
  } else if (np %in% c("peach")) {
    np_pl <- "peaches"
  } else if (np %in% c("city")) {
    np_pl <- "cities"
  } else if (np %in% c("auditorium")) {
    np_pl <- "auditoria"
  } else if (np %in% c("bottle of top-shelf liquor")) {
    np_pl <- "liquors"
  } else if (np %in% c("six-pack of beer")) {
    np_pl <- "beers"
  } else if (np %in% c("bottle of wine")) {
    np_pl <- "wine bottles"
  } else if (np %in% c("bush")) {
    np_pl <- "bushes"
  } else if (np %in% c("mouse den")) {
    np_pl <- "mouse holes"
  } else if (np %in% c("sprinting race")) {
    np_pl <- "sprints"
  } else if (np %in% c("child")) {
    np_pl <- "children"
  } else if (np %in% c("baby")) {
    np_pl <- "babies"
  } else if (np %in% c("platinum")) {
    np_pl <- "platinum statue"
  } else if (np %in% c("bronze")) {
    np_pl <- "bronze statues"
  } else if (np %in% c("pick-up truck")) {
    np_pl <- "pick up trucks"
  } else if ((np %in% c("plastic")) & (superordinate == "bracelets")) {
    np_pl <- "plastic bracelets"
  } else if (np %in% c("gold")) {
    np_pl <- "gold bracelets"
  } else if (np %in% c("metal")) {
    np_pl <- "metal bracelets"
  } else if ((np %in% c("plastic")) & (superordinate == "statues")) {
    np_pl <- "plastic statues"
  } else if (np %in% c(
    "wool", "wood", "fish", "ice cream", "garlic", "saffron", "coffee", "raspberries",
    "boysenberries",
    "strawberries", "sneakers", "chicken", "boots", "tuna", "pork", "sandals", "plastic", "instant pot"
  )) {
    np_pl <- np # the items left singular
  } else {
    np_pl <- paste(np, "s", sep = "")
  }
  return(np_pl)
}
```


We extract frequecies of the plural NPs and the adjusted superordinates from the Google Web 1T 5-gram corpus (except for some items). We exchange some superordinates for their synonyms in order avoid polysemy. 

```{r}
d.tidy.auto.classified.w.pl.np <- d.tidy.auto.match.adjust_super %>%
  rowwise() %>%
  mutate(
    np_pl = insert_plural_np(tolower(np), superordinate),
    superordinate.freq = superordinate,
    superordinate.freq = ifelse(stim_id == 90, "doors", superordinate.freq),
    superordinate.freq = ifelse(stim_id == 5, "writing tools", superordinate.freq),
    superordinate.freq = ifelse(superordinate == "venue", "venues", superordinate.freq),
    superordinate.freq = ifelse(superordinate == "dens", "animal dens", superordinate.freq) # avoid polysemy
  )

```

The corresponding subordinate and superordinate frequencies are added to each data point. 

```{r}
df.frequencies <- read_csv("../../data/class-elicitation-prereg-final/class-elicitation-final-plural_frequencies.csv")

d.tidy.auto.classified.w.frequency <- d.tidy.auto.classified.w.pl.np %>%
  left_join(., df.frequencies, by = c("np_pl" = "NPs")) %>% # add subordinate frequencies
  left_join(., df.frequencies, by = c("superordinate.freq" = "NPs")) %>% # add superordinate frequencies
  mutate(
    degree = ifelse(degree == "length_duration", "length", degree)
  )

df.mode.auto.final <- d.tidy.auto.classified.w.frequency %>%
  select(
    workerid, stim_id, degree, superordinate.freq, adj, adj_polarity,
    np, np_pl, np_expectations, mode_np, specific, Frequencies.x, Frequencies.y
  ) %>%
  mutate(
    superordinate_pl = superordinate.freq, NP_sg = np, NP_pl = np_pl,
    response = mode_np, subFreq = Frequencies.x, superFreq = Frequencies.y
  ) %>%
  select(
    workerid, stim_id, degree, superordinate_pl, adj, adj_polarity,
    NP_sg, NP_pl, np_expectations, response, specific, subFreq, superFreq
  )

# write_csv(df.mode.auto.final, "../data/class-elicitation-prereg-final/auto-classified-data-w-freqs-final.csv")
```



## Manual Response Processing 

We look at the responses that were not automatically classified (about 4000). We judge if the deviating responses are synonymous to our experimentally-supplied NPs or anticipated superordinates and adjust them in order to match to those NPs or superordinates. Deviant responses which occur frequently are left unchanged to check if any deviating response was the modal response for any particular NP-adj pair.

``` {r nonMatchedResps}
# look at the unique non-matched responses
d.tidy.auto.non_match <- anti_join(d.tidy.auto, d.tidy.auto.match)

length(d.tidy.auto.non_match$response)

# d.tidy.auto.non_match %>%
#   distinct(superordinate, np, context_sentence, adj, np_match, response, response_lemma, cleanedPhrase, specific, matchingSuper) %>%
#   View()
```

The goal is to extract the responses which were produced by at least 3 participants for the respective stimulus (NP-adj pair). The responses are lower-cased. 

``` {r nonMatchedResps-lemmatize}
d.tidy.auto.non_match <- d.tidy.auto.non_match %>%
  mutate(response = tolower(response))

d.tidy.auto.non_match <- d.tidy.auto.non_match %>%
  mutate(
    response_hand_lemma = response_lemma
  )
```

The lemmatized and corrected reponses are counted by-stimulus; we keep those which were produced by at least 3 participants. 869 non-matched responses (20.6%) were produced less than 3 times and are dropped. 

``` {r nonMatchedResps-grab3}
# d.tidy.auto.non_match.lemma.counts <- d.tidy.auto.non_match %>% count(stim_id, response_hand_lemma)

# MH, I found it illuminating to look at: d.tidy.auto.non_match %>% count(response_hand_lemma) %>% View()
# you can see if there are more misspellings or lemmatizations required easily by sorting by response_hand_lemma 

# d.tidy.auto.non_match.grab3 <- d.tidy.auto.non_match.lemma.counts %>%
#   right_join(., d.tidy.auto.non_match, by = c("stim_id", "response_hand_lemma")) %>%
#   filter(n >= 3)
# MH: this code replaces the need for the other two lines above this

d.tidy.auto.non_match.grab3 <- d.tidy.auto.non_match %>% 
  group_by(stim_id, response_hand_lemma) %>% 
  mutate(n = n()) %>% 
  filter(n >= 3)

nrow(d.tidy.auto.non_match) - nrow(d.tidy.auto.non_match.grab3)
(nrow(d.tidy.auto.non_match) - nrow(d.tidy.auto.non_match.grab3)) / nrow(d.tidy.auto.non_match)
```


The data is manually classified into the following types of comparison classes:
- subordinate ('sub')
- superordinate ('super')
- super-superordinate ('supersuper'): comparison classes that are more general than the anticipated superordinate categories (e.g. 'things' relative to the anticipated 'musical instruments')
- different hierarchy ('diff'): the comparison class is outside of the anticipated hierarchy (e.g. more specific than the anticipated superordinate: "cats" instead of animals for stim 8)
- "NA" for invalid responses 

The by-response hand-classifications are put into the column 'hand_cc'.

Most classifications are read from a dataframe and are classifications from a produced response (a string) to a categorization. Some of these judgments are adjective-NP (item) specific, and these are performed after reading the dataframe with `case_when`. 

``` {r manualCC}
# look at distinct responses
d.tidy.auto.non_match.grab3.noFailedRef %>%
  distinct(stim_id, superordinate, np, adj, response_hand_lemma) %>%
  View()

hand_cc_dict <- read_csv("text_processing/hand_comp_classes_dict.csv") %>%
  rowwise() %>%
  mutate(
    hand_cc = ifelse(is.na(hand_cc), "NA", hand_cc)
  )

hand_cc_df <- pull(
  hand_cc_dict,
  hand_cc
) %>%
  set_names(pull(hand_cc_dict, hand_cc_lemma))

d.auto.non_match.hand_cc <- d.tidy.auto.non_match.grab3.noFailedRef %>%
  mutate(
    hand_cc = str_replace_all(response_hand_lemma, hand_cc_df)
  ) %>%
  # rowwise() %>%
  mutate(
    hand_cc =
      case_when(
        response_hand_lemma == "appliances" & stim_id == 61 ~ "supersuper",
        response_hand_lemma == "appliances" & stim_id == 75 ~ "diff",
        response_hand_lemma == "cans" & stim_id == 81 ~ "sub",
        response_hand_lemma == "color" & stim_id == 2 ~ "supersuper",
        response_hand_lemma == "color" & stim_id == 70 ~ "diff",
        response_hand_lemma == "color" & stim_id == 2 ~ "supersuper",
        response_hand_lemma == "days" & stim_id == 76 ~ "diff",
        response_hand_lemma == "days" & stim_id == 77 ~ "diff",
        response_hand_lemma == "days" & stim_id == 72 ~ "diff",
        response_hand_lemma == "days" & stim_id == 73 ~ "diff",
        response_hand_lemma == "desserts" & stim_id == 3 ~ "supersuper",
        response_hand_lemma == "fabric" & stim_id == 13 ~ "diff",
        response_hand_lemma == "food" & stim_id == 50 ~ "diff",
        response_hand_lemma == "fruit" & stim_id == 9 ~ "NA",
        response_hand_lemma == "locations" & stim_id == 38 ~ "NA",
        response_hand_lemma == "person" & stim_id == 69 ~ "supersuper",
        response_hand_lemma == "places" & stim_id == 4 ~ "diff",
        response_hand_lemma == "places" & stim_id == 38 ~ "NA",
        response_hand_lemma == "places" & stim_id == 29 ~ "supersuper",
        response_hand_lemma == "places" & stim_id == 39 ~ "NA",
        response_hand_lemma == "places" & stim_id == 31 ~ "NA",
        response_hand_lemma == "places" & stim_id == 42 ~ "supersuper",
        response_hand_lemma == "room" & stim_id == 75 ~ "NA",
        response_hand_lemma == "room" & stim_id == 35 ~ "NA",
        response_hand_lemma == "room" & stim_id == 11 ~ "NA",
        response_hand_lemma == "streets" & stim_id == 37 ~ "NA",
        response_hand_lemma == "weather" & stim_id == 76 ~ "NA"
        TRUE ~ hand_cc
      )
  )

# drop the invalid responses classified as "NA"
d.auto.non_match.hand_cc.valid <- d.auto.non_match.hand_cc %>% filter(!(hand_cc == "NA"))

# write_csv(d.auto.non_match.hand_cc.valid, "../data/class-elicitation-prereg-final/full-classified-data-w-hand-class.csv")
```


## Modal Superordinate Responses
The responses that were not processed automatically are inspected in detail to find responses systematically deviating from the anticipated ones. 

### Superordinates for the Adjective Endorsement
Here, superordinate responses were extracted which deviated from the anticipated superordinates in all conditions (i.e. NPs and adejctives: 3x2). The superordinates for the item 5 and 77 were adjusted to the modal response extracted here in all data sets and were used in the adjective endorsement experiment. 

The data points form the full data set are grouped by stim id, NP expectation, adjective polarity and specificity and the number of occurances of each response is calculated. Then, the modal response is extracted. The responses are then coerced to the respective modal response (i.e. the modal response of the respective NP and adjective condition). Then those superordinates where the modal response deviates for all 6 items of a set (set is 6 variations of an item: 3 np_expectations x 2 adj_polarities) and the deviating modal response is the same for all the 6 are extracted .
``` {r}
# extract the mode response
d.tidy.resp.counts <- d.auto.non_match.hand_cc %>%
  group_by(stim_id, superordinate, np_match, np_expectations, adj_polarity, specific, response_lemma) %>%
  count() %>%
  mutate(n_unique_resps = n) %>%
  ungroup()

# insert the NP  where participants gave subordinate response, modal superordinate where they gave superordinate response in column 'mode'
d.tidy.resp.counts <- d.tidy.resp.counts %>%
  group_by(stim_id, superordinate, np_match, adj_polarity, specific) %>%
  mutate(mode = response_lemma[which.max(n)])


# analysis of modal responses
d.tidy.resp.counts.analysis <- d.tidy.resp.counts %>%
  rowwise() %>%
  mutate(
    isModeNP = containsString_responses(
      as.character(paste("_", np_match, "_", sep = "")), as.character(mode),
      np_match, as.character(paste("_", mode, "_", sep = ""))
    ),
    isModeSuper = containsString_responses(
      as.character(paste("_", superordinate, "_", sep = "")), as.character(mode),
      superordinate, as.character(paste("_", mode, "_", sep = ""))
    ),
    isModeNeither = sum(isModeNP, isModeSuper),
    mode = gsub("_", "", mode)
  ) # isModeNeither = 0 means that the mode response is different from anticipated NPs

d.tidy.resp.counts.analysis %>%
  filter(isModeNeither == 0) %>%
  distinct(stim_id, degree, superordinate, np_match, specific, adj_polarity, mode) %>%
  View()

d.tidy.resp.counts.analysis %>%
  filter(isModeNeither == 0) %>%
  distinct(stim_id, degree, superordinate, np_match, specific, adj_polarity, mode) %>%
  count(stim_id, mode) %>%
  filter(n >= 6) -> stim.ids.adjust

d.tidy.resp.counts.analysis %>%
  filter(isModeNeither == 0) %>%
  distinct(stim_id, degree, superordinate, np_match, specific, adj_polarity, mode) %>%
  right_join(., stim.ids.adjust, by = c("stim_id")) %>%
  View()
```

### Common Superordinate Responses

We further conduct a more detailed analysis of the modal responses.
For the responses that are not classified automatically (i.e. are not the anticipated suboridnate or superoridnate NPs, about n = 4.000), we investigate if there are _several distinct salient superordinate responses within each item_ (classified as superordinate: all the data points that remain not matched to a priori subordinates or superordinates after the analyses are tagged as superordinate). For example, we would like to see if for the item set 'food' (anticipated superordinate) - 'soup' - 'salad' - 'ice cream' _more than three participants_ provided any superordinate responses other than 'food'. We collapse across single NPs and adjective conditions within an item, i.e. we count the response as salient if at least three participants provided the response given any NP of the item (e.g. any of 'soup', 'salad', 'ice cream') and any of the adjective (positive or negative, 'hot' or 'cold'). If the response provided by the participant was provided by at least two other participants, the response is kept, otherwise it is substituted by the a priori superordinate. The corresponding frequencies are extracted for plurals of these salient responses.     

```{r}
d.tidy.super.counts <- d.auto.non_match.hand_cc %>%
  filter((specific == 0) & (matchingSuper == 0)) %>%
  group_by(stim_id, superordinate, response_lemma) %>%
  count() %>%
  mutate(n_unique_resps = n) %>%
  ungroup()

d.tidy.super.counts %>% filter(n_unique_resps >= 3) -> d.tidy.super.counts.common

d.tidy.super.counts %>%
  ungroup() %>%
  mutate(produced_super = ifelse(n_unique_resps >= 3, response_lemma, superordinate)) -> d.tidy.super.adjust
d.auto.non_match.hand_cc %>%
  filter((specific == 0) & (matchingSuper == 0)) %>%
  left_join(., d.tidy.super.adjust, by = c("stim_id", "superordinate", "response_lemma")) -> d.nonMatch.adjustSuper

# get number of data points which passed the grab-3 criterion
d.nonMatch.adjustSuper %>% filter(produced_super != superordinate) # n = 2885

# get the distinct superordinates for the frequency extraction
d.nonMatch.adjustSuper %>% distinct(produced_super) -> distinctSuper
distinctSuper %>%
  rowwise() %>%
  filter(str_detect(produced_super, ".s$")) %>%
  as.list() %>%
  .$produced_super -> pluralSuper
# anti_join(distinctSuper, pluralSuper) %>% View()
super_plural <- function(n, pluralSuper) {
  if (n %in% c("music", "people", "food", "furniture", "decor", "jewelry", "wood", "weather", "fish", "transportation", "times of day", "cookware", "traffic")) {
    n_pl <- n
  } else if (n %in% pluralSuper) {
    n_pl <- n
  } else if (n == "box") {
    n_pl <- "boxes"
  } else if (n == "city") {
    n_pl <- "cities"
  } else {
    n_pl <- paste(n, "s", sep = "")
  }
  return(n_pl)
}

distinctSuper %>%
  rowwise() %>%
  mutate(produced_super_pl = super_plural(produced_super, pluralSuper)) -> allSuper

# write_csv(allSuper, "../data/class-elicitation-prereg-final/hand-classified-produced-distinct-super-pl.csv")

d.nonMatch.adjustSuper <- d.nonMatch.adjustSuper %>%
  rowwise() %>%
  mutate(produced_super_pl = super_plural(produced_super, pluralSuper))

d.nonMatch.adjustSuper.filter <- d.nonMatch.adjustSuper %>%
  rowwise() %>%
  mutate(
    degree = ifelse(degree == "length_duration", "length", degree),
    superordinate_pl = produced_super_pl,
    superordinate_pl = ifelse(superordinate_pl == "dens", "animal dens", superordinate_pl),
    superordinate_pl = ifelse(superordinate_pl == " kitchens", "kitchens", superordinate_pl),
    superordinate_pl = ifelse(superordinate_pl == " furnitures", "furniture", superordinate_pl),
    superordinate_pl = ifelse(superordinate_pl == " fabrics", "fabrics", superordinate_pl),
    superordinate_pl = ifelse(superordinate_pl == " woods", "wood", superordinate_pl),
    NP_pl = insert_plural_np(tolower(np), superordinate)
  ) %>%
  select(workerid, stim_id, degree, superordinate_pl, adj, adj_polarity,
    NP_sg = np, NP_pl, np_expectations, response = produced_super_pl, specific
  )

df.produced.super.freqs <- read_csv("../../data/class-elicitation-prereg-final/hand-classified-produced-super-pl-frequencies.csv")

d.nonMatch.adjustSuper.filter.w.freqs <- d.nonMatch.adjustSuper.filter %>%
  left_join(., df.frequencies, by = c("NP_pl" = "NPs")) %>%
  left_join(., df.produced.super.freqs, by = c("superordinate_pl" = "NPs"))

d.nonMatch.adjustSuper.filter.w.freqs <- d.nonMatch.adjustSuper.filter.w.freqs %>%
  select(workerid, stim_id, degree, superordinate_pl, adj, adj_polarity, NP_sg,
    NP_pl, np_expectations, response, specific,
    subFreq = Frequencies.x, superFreq = Frequencies.y
  )

# write_csv(d.nonMatch.adjustSuper.filter.w.freqs, "../data/class-elicitation-prereg-final/hand-classified-supers-w-produced-super-w-freqs.csv")
```

## Full Data with Common Superordinates

Here, a dataframe containing the full processed data where the superordinates are the common superordinates extracted above by the 3-participants rule is created. Hence, the subordinate responses are coerced to the NPs and the superordinate responses are either unchanged if at least three such responses were produced for the respective item or coerced to the anticipated superordinate. The respective subordinate and superordiunate frequencies are added to each data point.

``` {r}
# create full df with produced grab-3 superordinates

d.tidy.auto.classified.w.frequency %>% 
 filter((specific == 1) | (matchingSuper == 1)) %>%
  select(workerid, stim_id, degree,
    superordinate_pl = superordinate.freq,
    adj, adj_polarity, NP_sg = np, NP_pl = np_pl, np_expectations,
    response = mode_np, specific, subFreq = Frequencies.x, superFreq = Frequencies.y
  ) %>%
  rbind(., d.nonMatch.adjustSuper.filter.w.freqs) -> d.full.w.produced.super

# write_csv(d.full.w.produced.super, "../data/class-elicitation-prereg-final/full-classified-data-w-produced-super.csv")
```
