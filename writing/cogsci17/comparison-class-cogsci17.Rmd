---
title: "Cheap cars, expensive coffee: Understanding comparison classes in vague language"
bibliography: [comparison-class.bib, library.bib]
csl: "apa6.csl"
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Michael Henry Tessler} \\ mtessler@stanford.edu \\ Department of Psychology \\ Stanford University
    \And {\large \bf Michael Lopez-Brau} \\ author2@university.edu \\ Department of ... \\  University
    \And {\large \bf Noah D. Goodman} \\ ngoodman@stanford.edu \\ Department of Psychology \\ Stanford University}

abstract: 
    "Gradable adjectives (e.g., *expensive*) exhibit a sensitivity to context that poses a challenge to quantitative theories of language understanding. 
    In particular, the issue of how to derive a comparison class---the set of entities against which a target object is implicitly compared---in context has yet to be addressed by formal models of adjective interpretation. 
    We introduce a Rational Speech Act model that respresents the implicit comparison class as a random variable inferred via pragmatic reasoning.
    We find this model makes the prediction that the level of abstraction of the comparison class (e.g., expensive relative to *toasters* or *ovens* vs. *kitchen appliances*) is expected to be modulated by the properties of the target object under consideration (e.g., a toaster or oven).
    We test this prediction using a paraphrase experiment.
    Quantative predictions of the model rely upon quantitative details of relevant prior distributions.
    We introduce a novel Bayesian data-analytic method for inferred participants' relevant prior knowledge by asking simple, natural language questions.
    "
    
keywords:
    "comparison class; pragmatics; Bayesian cognitive model; Bayesian data analysis"
    
output: cogsci2016::cogsci_paper
---

\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\definecolor{Orange}{RGB}{255,153,0}

\newcommand{\red}[1]{\textcolor{Red}{#1}}  
\newcommand{\ndg}[1]{\textcolor{Green}{[ndg: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}}  
\newcommand{\mlb}[1]{\textcolor{Orange}{[mlb: #1]}}

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(tidyverse)
library(xtable)
library(rwebppl)
library(langcog)
library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

HPDhi<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

HPDlo<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```

<!--
# Outline

1. We introduce an extension to RSA that does inference over what is the comparison class.

2. We take a simple case, where the comparison class is either a sub- or super-ordinate category. Just playing with the parameters off the model, we see this predicted (qualitative) interaction:

- When the subclass has a high mean relative to the superclass, positive form adjectives signal the superclass, and negative form signals the subclass

- When the subclass has a low mean relative to the superclass, positive form adjectives signal the subclass, and negative form signals the superclass

3. We test this predictions on 5 scales (Expt. 1)

- We see the qualitative effect on all 5 scales, but there is considerable heterogeneity among the scales.

4. This heterogeneity might be attributed to differences in the quantitative details (i.e., the parameters) of the subclass vis-a-vis the superclass

- We can perform BDA to see if this is true, but this model is actually overparameterized.

- We can simplify by assuming each superclass has a unit-normal prior, and infer the mean and standard deviation for each subclass prior.

- That’s 2 parameters for each subclass, and we only have 2 items for each subclass (namely, positive and negative form adjectives e.g., “tall” and “short” bball players)

5. We estimate the prior parameters by asking other questions of our model that should (a) access the same priors; and (b) not add other parameters

so we can ask a vague speaker question (Expt 2. [VPE])

This will alleviate the overparameterization problem and is, in general, a new way of testing language understanding models without having to explicitly measure priors
-->

If you're going to San Francisco, be sure to set aside a few extra dollars for coffee. 
It's good, but expensive.
By expensive, we mean *expensive relative to coffee elsewhere*, and not *expensive relative to other things in San Francisco*: Rent in San Francisco is expensive in a different way. 
This may seem obvious, and yet adjectives like *expensive* derive their relatively precise meanings from the category of things against which the target entity (e.g., the price of a good cup of coffee in San Francisco) is compared.
This *comparison class* is not often explicitly stated, bur rather is latent in the discourse.

Adjectives like *cheap* and *expensive*, *cold* and *warm* are vague descriptions of an underlying quantitative scale (e.g., price, temperature).
Contemporary linguistic theories posit that the truth-conditional semantics of such vague utterances are simple thresholds on the measure [@Kennedy2007].
For example, a good cup of coffee is expensive if its price is greater than some threshold number of dollars.
The crux of such theories rests on the fact that this threshold is relative to a *comparison class* of other possible entities. 
A good cup of coffee in San Francisco is expensive *relative to* other cups of coffee and not *relative to* other things you could buy in San Francisco (including, e.g., a Tesla automobile).

@Lassiter2013 demonstrated that listener's with relevant world knowledge (e.g., prices of coffee) can use pragmatic principles to arrive at a context-dependent meaning of a gradable adjective (e.g., expensive) assuming nothing in particular about what the adjective means out of context. 
They elaborate the Rational Speech Act theory [for a review, see @Goodman2016] such that the truth-conditional threshold for the adjective semantics (i.e., the point at which something becomes expensive) comes from an uninformed prior distribution: *a priori* anything could be expensive.
Listeners arrive at context-sensitive meanings by integrating their prior beliefs (e.g., knowledge of what a cup of coffee should cost) with general principles of communication: be truthful, be informative. 
The result is vague language understanding that displays context-sensitivity and admits borderline cases [@Lassiter2013; @Lassiter2015].
See @Qing2014 for a related but alternative derivation of a probabilistic pragmatics model of gradable adjective interpretation.
\mht{this paragraph sucks}

In @Lassiter2013's theory of adjective interpretation, the comparison class is implicit in the listener's prior belief distribution.
But how does a listener settle on the appropriate comparison class, when none is specifically articulated by the speaker?
This question is not just an issue for gradaable adjectives but in fact for any vague language that can be modeled using a threshold semantics [e.g., generic language, see @Tessler2016]

<!--
The comparison class can depend upon the target object (as in the examples above) as well as the physical context or the Question Under Discussion.
@Ebeling1994 demonstrate that 2-4 year olds understand the context-sensitivity of the words "big" and "little," finding the appropriate object whether the object is in a physical context ("big" relative to other objects in a scene), a functional context ("big" relative to its intended use), or out of context ("big" relative to an implicit comparison class). 
-->

In this paper, we argue that pragmatic principles can be used to resolve the comparison class in context.
We extend the Rational Speech Act theory of @Lassiter2013 to include uncertainty over the comparison class.
We test this model in a simplified setting, where the comparison class could either be a subordinate or superordinate class (e.g., toasters vs. kitchen appliances).
In this simplified setting, we find the model predicts the level of abstraction (sub vs. superordinate) of a comparison class depends upon the quantitative details of the relevant prior beliefs (e.g., the prices of toasters vs. the prices of kitchen appliances in general). 
We test this prediction using a paraphrase experiment (Expt. 1).
Quantitative predictions for Bayesian models (including this one) depend upon the quantitative details of listeners' prior distributions over various scales.
Because it may be difficult for human participants to estimate quantities accurately, we introduce a novel Bayesian data-analytic technique for learning about listeners' prior belief distributions using convergent language understanding tasks.


# Computational model

We elaborate the Rational Speech Act model for vague language understanding [@Lassiter2013; @Lassiter2015] by introducing uncertainty over the class of entities against which the target entity is compared--- the comparison class $c$.
This uncertainty is posited at the level of the pragmatic listener, and thus is resolved using pragmatic reasoning (i.e., the pressures to be truthful and informative).
In addition to the uncertainty over the comparison class $c$, the pragmatic listener also have uncertainty over the value of the degree $x$ (e.g., the height of the person) and the semantic threshold variable $\theta$ as in @Lassiter2013. 

\begin{align}
L_{1}(x, c, \theta \mid u) &\propto S_{1}(u \mid x, c, \theta) \cdot P(x \mid c_{sub}) \cdot P(c) \cdot P(\theta) \label{eq:L1}\\
S_{1}(u \mid x, c, \theta) &\propto \exp{(\alpha_1 \cdot \ln {L_{0}(x \mid u, c, \theta)})} \label{eq:S1}\\
L_{0}(x \mid u, c, \theta) &\propto {\delta_{[[u]](x, \theta)} \cdot P(x \mid c)}. \label{eq:L0}
\end{align}

Uncertainty about the value of the degree $x$ is always with respect to a comparison class $c$: $P(x \mid c)$. 
That is, the plausible heights of basketball players is different than the plausible heights of people in general. 

## Model predictions

As a first test of this pragmatic theory, we consider a simple case: 
The comparison class is either a subordinate level category (e.g., basketball players) or a superordinate level category (e.g., people *in general*). 
Thus, $c \sim \text{UniformDraw}([c_{sub}, c_{super}])$.
We also assume the listener $L_1$ knows the target entity is a member of the subordinate class (i.e., "John is a basketball player."): $P(x \mid c_{sub})$.
Then, the listener $L_1$ tries to uncover the speaker's implicit comparison class $c$ by incorparting what she knows about the subordinate level category (e.g., basketball players) $P(x \mid c_{sub})$ and the superordinate level category (e.g., people in general) $P(x \mid c_{super})$.

The likely comparison class will depend on the details of the prior distributions over the sub- and super-ordinate level classes (e.g., the heights of basketball players and people in general) as well as the polarity of the gradable adjective (i.e., *tall* vs. *short*).
For simplicity, we assume the prior distribution over the degree for the superordinate class is a unit-normal distribution $x_{super} \sim \mathcal{N}(0, 1)$ and explore the model predictions as we vary the mean and standard deviation for the prior of the subordinate class.

```{r modelSchematics, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "Model predictions"}
## to do, pass in the prior params and positive / negative form adjective as arguments to webppl program

model.path <- "/Users/mht/Documents/research/comparison-class/models/"
mp <- webppl(program_file = paste(model.path, "ccrsa.wppl", sep = ""),
       packages = c( paste(model.path, "node_modules/adjectiveRSA", sep = "") ))

ggplot(mp, aes(x = support, y = prob, fill = support))+
  geom_bar(stat= 'identity', position = position_dodge())+
  scale_fill_brewer(palette = "Set1")+
  theme_bw()
```

We see that as the mean of the subordinate prior becomes greater than the superordinate prior, positive form adjectives (e.g., *tall*, *expensive*, *warm*) will be more likely to imply a superordinate comparison class (e.g., *people in general*), while negative form adjectives (e.g., *short*, *cheap*, *cold*) will imply a subordinate class (e.g., *basketball players*). 
The opposite pattern is observed for subordinates priors with a mean substantially lower than the superordinate prior. 
We test these predictions in our first experiment.

# Experiment 1: Comparison class inference

## Methods

### Participants

<!--
Note: We are collecting N = 150 for each experiment. Because each participant reads have of the prompts, we expect about n = 75 per item. Simulations reveal that with n = 75, a 95% CI will have maximum width of about 0.2 - 0.25. Note that maximum width occurs when true probability is 0.5. 
-->

```{r, eval = F, echo=F}
## simulations to determine width of 95% CI for 2AFC data assuming different sample sizes and true binomial probabilities 

### not written efficiently... will take ~10 minutes to run 
n_participants <- c(50, 75, 100)
true_probs <- c(0.1, 0.3, 0.5)
simulations <- data.frame()
for (n in n_participants){
  for (p in true_probs){
    for (i in seq(1, 25)){
      simulations <- bind_rows(simulations,
            bind_rows(data.frame(label = c("a"), 
                       response = rbinom(n =n, size = 1, prob = p)),
                data.frame(label = c("b"), 
                           response = rbinom(n =n, size = 1, prob = p))) %>%
            group_by(label) %>% 
            multi_boot_standard(column = "response") %>%
            mutate(width = ci_upper - ci_lower) %>%
          ungroup() %>%
          summarize(w = mean(width)) %>%
            mutate(n = n, p = p, i=i)
      )
    }
  }
}

ggplot(simulations, aes(x = w))+
 geom_histogram()+
 facet_grid(n~p)

```

### Materials

\mht{We should make a nice table showing the degrees, sub ordinate classes, and super ordinate classes}.

Here are some notes about how to make tables:

Number tables consecutively; place the table number and title (in
10 point) above the table with one line space above the caption and
one line space below it, as in Table 1. You may float
tables to the top or bottom of a column, set wide tables across both
columns.

You can use the xtable function in the xtable package.

```{r xtable, results="asis"}
n <- 100
x <- rnorm(n)
y <- 2*x + rnorm(n)
out <- lm(y ~ x)

tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2), 
                      caption = "This table prints across one column.")

print(tab1, type="latex", comment = F, table.placement = "H")
```

### Procedure

## Results

# Experiment 2: Vague speakers

\begin{align}
S_{2}(u \mid c_{sub}) &\propto \exp{(\alpha_2 \cdot \ln{L_1(x, \theta \mid u, c_{super})})} \label{eq:S2} \\
L_{1}(x, \theta \mid u, c_{super}) &\propto S_{1}(u \mid x, c_{super}, \theta) \cdot P(x \mid c_{sub}) \cdot P(\theta) \label{eq:L1a}
\end{align}

## Methods

### Participants




### Materials

### Procedure

## Results

# Discussion

\begin{enumerate}
\item Speaker knowledge: If you're a basketball scout, and you say of a player that "He is tall." it means "Tall relative to basketball players"
\item QUD: If we're deciding what to do on Friday night, you say "The opera is expensive" it means "Expensive relative to other things we could do on Friday night"
\item Hyperbole / *normative* comparison classs: If we listen to a lecture, and you say "That *was long*.", it means "Long relative to how long I think it should have been." If we go out for pasta, and you ask how it was, and I say "it was expensive" it means "expensive relative to how much it should have been given the quality".
\end{enumerate}

<!--
For general information about authoring in markdown, see **[here](http://rmarkdown.rstudio.com/authoring_basics.html).**

First level headings should be in 12 point , initial caps, bold and
centered. Leave one line space above the heading and 1/4~line space
below the heading.

## Second-Level Headings

Second level headings should be 11 point , initial caps, bold, and
flush left. Leave one line space above the heading and 1/4~ line
space below the heading.

### Third-Level Headings

Third-level headings should be 10 point , initial caps, bold, and flush
left. Leave one line space above the heading, but no space after the
heading.

# Formalities, Footnotes, and Floats

Use standard APA citation format. Citations within the text should
include the author's last name and year. If the authors' names are
included in the sentence, place only the year in parentheses, as in
[-@NewellSimon1972a], but otherwise place the entire reference in
parentheses with the authors and year separated by a comma
[@NewellSimon1972a]. List multiple references alphabetically and
separate them by semicolons [@ChalnickBillman1988a; @NewellSimon1972a]. 
Use the et. al. construction only after listing all the authors to a
publication in an earlier reference and for citations with four or
more authors.

For more information on citations in R Markdown, see **[here](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html#citations).**

## Footnotes

Indicate footnotes with a number\footnote{Sample of the first
footnote.} in the text. Place the footnotes in 9 point type at the
bottom of the page on which they appear. Precede the footnote with a
horizontal rule.\footnote{Sample of the second footnote.}

## Figures

All artwork must be very dark for purposes of reproduction and should
not be hand drawn. Number figures sequentially, placing the figure
number and caption, in 10 point, after the figure with one line space
above the caption and one line space below it. If necessary, leave extra white space at
the bottom of the page to avoid splitting the figure and figure
caption. You may float figures to the top or bottom of a column, or
set wide figures across both columns.

## Two-column images

You can read local images using png package for example and plot 
it like a regular plot using grid.raster from the grid package. 
With this method you have full control of the size of your image. **Note: Image must be in .png file format for the readPNG function to work.**

You might want to display a wide figure across both columns. To do this, you change the `fig.env` chunk option to `figure*`. To align the image in the center of the page, set `fig.align` option to `center`. To format the width of your caption text, you set the `num.cols.cap` option to `2`.

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
img <- png::readPNG("figs/walrus.png")
grid::grid.raster(img)
```

## One-column images

Single column is the default option, but if you want set it explicitly, set `fig.env` to `figure`. Notice that the `num.cols` option for the caption width is set to `1`.

```{r image, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image."}
img <- png::readPNG("figs/lab_logo_stanford.png")
grid::grid.raster(img)
```


## R Plots

You can use R chunks directly to plot graphs. And you can use latex floats in the
fig.pos chunk option to have more control over the location of your plot on the page. For more information on latex placement specifiers see **[here](https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions)**

```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "R plot" }
x <- 0:100
y <- 2 * (x + rnorm(length(x), sd = 3) + 3)

ggplot2::ggplot(data = data.frame(x, y), 
       aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```


## Tables

Number tables consecutively; place the table number and title (in
10 point) above the table with one line space above the caption and
one line space below it, as in Table 1. You may float
tables to the top or bottom of a column, set wide tables across both
columns.

You can use the xtable function in the xtable package.

-->

# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.




<!--
## Experiments

See all the items [here](http://stanford.edu/~mtessler/comparison-class/experiments/js/examples-2.js), or see the listener experiment (with all the items) [here](http://stanford.edu/~mtessler/comparison-class/experiments/listener-1.html).

\begin{enumerate}

\item \textbf{Stimuli}
  \subitem Currently we have 40 unique items, made up of 6 scales x 2 (positive and negative form adjectives)
  \subitem Note we are using temperature that is perceived both through touching and temperature that is perceived in the whole body (touching objects vs. the weather). For the weather, it is really about speaker's beliefs--their own subjective comparison class (e.g., John think its cold because he's from Southern California).
  \subitem 3 or 4 contexts by item (different targets of reference)
  \subitem Example: Gary buys a [television, book, iPhone] and picks it up. He says, ``This is heavy.'' 

\item \textbf{Comparison class elicitation}
  \subitem We have run a pilot using the paraphrase technique with the helper phrases "for a" and "relative to." "For a" produced more reliable results, so we'll use that going forward.
  \subitem Example: Gary buys a television and picks it up. He says, ``This is heavy.'' 
  \subitem \textbf{Dependent measure}: What do you think Gary meant? ``This is heavy \textbf{for a} ...'' (fill in the blank)
  \subitem \textbf{Data analysis}: Take modal response, or top 2, and use those in the prior elicitation task.

\item \textbf{Prior elicitation}
  \subitem This will refer to the comparison class. 
  \subitem \textbf{Dependent measure}: What do you think is the weight of a television? Provide number and units (units from a set from a drop-down menu).

\item \textbf{Language understanding (Listener task)}
  \subitem Same stimuli as the comparison class elicitation.
  \subitem \textbf{Dependent measure}: same as prior elicitation.

\end{enumerate}
# Model 

uRSA with lifted variable. 
Plug in different priors.

# Data anlaysis

Probably something similar to the habituals paper. 
Assume log-normals, do BDA on the prior data.

# Current concerns

\begin{enumerate}

\item In the Justine-way of doing these kinds of experiments, for the prior elicitation, we would have the same context sentence (``Gary buys a television and picks it up.'') without the adjective sentence, and ask about the likely weight.
What does our intermediate comparison class elicitation step buy us?

\item For many of the our items, it seems that the comparison class we're going to get is the class of the target objects (e.g., televisions, cups of coffee, weather in Southern California)... I have the feeling that some items (e.g., a 30 year old who is tall) have more general classes (e.g., tall for an adult, for a woman) while others (e.g., a 4 year old boy who is tall) have more specific classes (i.e., tall for a 4 year old). This example may be unique / idiosyncractic, but also may suggest that the comparison class needs to be a relative homogeneous category (e.g., 4 year olds are really different than 2 year olds, whereas 30 vs. 28 year olds not so much). If this is interesting, should we try to move our stimuli more in that direction? Any thoughts? 

\end{enumerate}

-->

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
