---
title: "Warm (for winter): Comparison class understanding in vague language"
bibliography: [comparison-class.bib, library.bib]
csl: "apa6.csl"
document-params: "10pt, letterpaper"
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{gensymb}
  - \usepackage{tikz}
  #- \usepackage{stfloats}

author-information: >
  \author{{\large \bf Michael Henry Tessler$^1$} (mtessler@stanford.edu) \and {\large \bf Michael Lopez-Brau$^2$} (lopez\_mic@knights.ucf.edu) \\
  {\large \bf Noah D. Goodman$^1$} (ngoodman@stanford.edu) \\
  $^1$Department of Psychology, Stanford University,
  $^2$Department of Electrical \& Computer Engineering, University of Central Florida}

abstract:
    "The words we say are often too vague to have a single, precise meaning, and only make sense in context. 
    The context, however, can also be underspecified, leaving the listener in the dark about both the speaker's intended meaning and about the context through which the listener is to make sense of the conversation.
    For example, *It's warm outside* could mean it's warm relative to other days of the year, or just relative to the current season (e.g., it's warm for winter).
    The issue is that *warm* conveys that the temperature is high relative to some comparison class, but little is known about how a listener decides upon a comparison class. 
    Here, we propose the resolution of a comparison class in context is a pragmatic inference driven by world knowledge and internal models of speech production.
    We introduce a Rational Speech Act model and derive two qualitative predictions from the model, which we validate using a paraphrase experiment to measure listeners' beliefs about the likely comparison class.
    We then produce quantitative predictions from the model by asking follow-up questions to the model combined with a novel Bayesian data analytic technique. 
    We conclude that the listeners are remarkably flexible in their ability to infer speakers' intended reference class when they are absent from the context."

keywords:
    "comparison class; pragmatics; Bayesian cognitive model; Bayesian data analysis"

output: cogsci2016::cogsci_paper
---

\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\definecolor{Orange}{RGB}{255,153,0}

\newcommand{\red}[1]{\textcolor{Red}{#1}}  
\newcommand{\ndg}[1]{\textcolor{Green}{[ndg: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}}  
\newcommand{\mlb}[1]{\textcolor{Orange}{[mlb: #1]}}

```{r global_options, include=FALSE}
rm(list=ls())

# set local path for the repo
if (grepl("michael", getwd())) {
  project.path <- "/media/michael/Data/Desktop/comparison-class/"
} else if (grepl("mht", getwd())) {
  project.path <- "/Users/mht/Documents/research/comparison-class/"
} else {
  project.path <- "/Users/ngoodman/comparison-class/"
}

knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop=F, fig.pos="tb", fig.path='figs/', echo=F, warning=F, cache=F, message=F, sanitize=T)

```

```{r, libraries}
library(png)
library(grid)
library(gridExtra)
library(tidyverse)
library(xtable)
library(rwebppl)
library(langcog)
library(coda)
library(lme4)
library(lmerTest)
library(data.table)
#install.packages("ggthemes")
library(ggthemes)
estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

HPDhi<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

HPDlo<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```

```{r}
theme_set(theme_minimal(8))
```

# Introduction

When it's warm outside, it's still useful to know whether we're in July or January.
A warm day in July could be 80\degree F while a warm one in January might not get above 60\degree F.
The predicate "warm" is vague in the sense that there are borderline cases of being warm--interlocutors can faultlessly disagree as to whether or not it is warm since what it means to be warm is relative to a relevant *comparison class*.

Comparison classes are uncontroversial in the study of vague language. 
Even 2- or 3-year-olds understand that the meaning of the words "big" and "little" depend upon the context: 
An object can be "big" relative to other objects in a scene (i.e., its physical context), 
an object can be "big" relative to the size it should be for completing its intended function, 
or an object can just be "big" [or, big relative to an implicit comparison class; @Ebeling1994]. 
\mht{$\leftarrow$ not sure if this is the best evidence for my topic sentence}
Adult judgments of the felicity for gradable adjectives like "dark" or "light", "short" or "tall" depend upon fine-grained details of the statistics of the comparison class [@Solt2012; @Qing2014].
It is not well understood, however, how a comparison class becomes contextually-salient. 
The problem is an obvious one because any particular object of discourse can be conceptualized or categorized in multiple ways, giving rise to multiple possible comparison classes. 
A warm day in January could be warm for the time of year (i.e., *warm relative to other days in January*^[
also, *in this location*, where the speaker is]
or it could just be warm (i.e., *warm relative to any day of the year*)

We propose that the selection of a comparison class with respect to which vague languages gets interpreted is arrived upon through a pragmatic reasoning process.
<!--We propose that vague language gets interpreted with respect to a particular comparison class via a pragmatic reasoning process.-->
We introduce a novel language understanding model that can resolve uncertainty about the likely reference class alongside the uncertainty known to be important for modeling vague language understanding (namely, uncertainty about the world and uncertainty about the precise meaning of the vague speech act).
From this model, we derive two qualitative predictions:
(1) Ceteris paribus, a listener should prefer reference classes that have lower variance because the vague utterance will have a more specific meaning under a lower variance reference class. 
(2) When the object of discourse is a member of a subordinate class with a mean significantly greater than the mean of a higher level class (e.g., a day in Summer has an expected temperature higher than the average across the whole year), listeners should prefer the higher level (or, superordinate) class because the vague utterance is more likely to be true of the higher level class. 
The opposite pattern is predicted to hold for subordinate classes low on the scale (e.g., days in Winter). 
We test these predictions in an experiment designed to elicit the comparison class.

Quantitative predictions of the model will depend on the quantitative details of the relevant world knowledge.
This could be measured by having participants estimate quantities or give likelihood judgments [@FrankeEtAl2016].
Instead, we build a Bayesian data-analytic model to introduce uncertainty over these parameters and resolve the uncertainty by asking similar natural language questions in the domains of inquiry. 
This represents a new possibility for Bayesian models of cognition and language: by building more complete and coherent models of language, additional parameters can be estimated reliably by asking the model to give multiple judgments on different tasks.

<!--
"It's warm outside" when heard in July means something very different than when heard in January.
Warm is vague,
When heard in Winter, "It's warm" might mean it's 50 degrees; in Summer, maybe 80.
-->

# Language understanding with comparison class uncertainty

Adjectives like *warm* and *cold*, *cheap* and *expensive*,  are vague descriptions of an underlying quantitative scale (e.g., temperature, price).
Contemporary linguistic theories posit that the truth-conditional semantics of such vague utterances are simple thresholds on the measure [@Kennedy2007].
For example, the weather is *warm* if its temperature is greater than some threshold number of degrees.
The crux of such theories rests on the fact that this threshold is derived relative to a *comparison class* of other possible entities.
A day in Winter can be warm *relative to* other days in Winter but probably not warm relative to all days of the year.

The comparison class can be thought of as a probability distribution over degrees on a scale [@Lassiter2013; @Qing2014a].
We adopt a probabilistic model of adjectival interpretation that is derived from general principles of language understanding [@Lassiter2013].
The model is an extension of the Rational Speech Act theory of language understanding [for a review see: @Goodman2016] and uses a simple threshold semantics for adjectives $[[u]]: x > \theta$ (i.e., warm means greater than some temperature).
Uncertainty is placed over the threshold $\theta \sim \text{Uniform}(0, 1)$ and is resolved by the pragmatic listener reasoning about the likely values of the degree $P(x)$, given a comparison class.
Such a model reasons about a comparison class, but doesn't have anything to say about where the comparison class comes from.
The issue of the comparison class touches upon not only gradable adjectives, but in fact any language that can be modeled with an underspecified threshold criterion including generic language [@Tessler2016] and vague quantifiers [@SchollerFranke2015].
How does a listener settle on the appropriate comparison class, when none is specifically articulated by the speaker?

When a listener hears only that "It's warm outside" without an explicit comparison class (e.g., "...relative to other days in Winter."), we imagine that a listener must infer the comparison class by imagining the likely the completion of the explicit sentence (i.e., must fill in the comparison class), in a way analagous to noisy-channel models of production and comprehension [@Bergen2016].
She does this using her prior knowledge of what comparison classes are likely to be talked about: $P(c)$.
We posit that this knowledge is the listener's internal model of speech production of different classes of entities, and thus this comparison class prior should include information about the frequency of different classes. 
\mht{mention "basic level" here?}

```{r wpplHelpers}
webpplHelpers <- '
var round = function(x){
  return Math.round(x*10)/10
}

var distProbs = function(dist, supp) {
  return map(function(s) {
    return Math.exp(dist.score(s))
  }, supp)
}

var KL = function(p, q, supp) {
  var P = distProbs(p, supp), Q = distProbs(q, supp);
  var diverge = function(xp,xq) {
    return xp == 0 ? 0 : (xp * Math.log(xp / xq) );
  };
  return sum(map2(diverge,P,Q));
};

var exp = function(x){return Math.exp(x)}
'
```

```{r rsaPrior}
priorForRSA <- '
var binParam = 3;

var stateParams = {
  sub: paramsFromR.priorParams.sub[0],
  super: paramsFromR.priorParams.super[0]
};

var stateVals = map(
  round,
  _.range(stateParams.super.mu - 3 * stateParams.super.sigma,
          stateParams.super.mu + 3 * stateParams.super.sigma,
          stateParams.super.sigma/binParam)
);

var stateProbs = {
  sub: map(function(s){
    Math.exp(Gaussian(stateParams.sub).score(s))+
    Number.EPSILON
  }, stateVals),
  super: map(function(s){
    Math.exp(Gaussian(stateParams.super).score(s))+
    Number.EPSILON
  }, stateVals)
};

var statePrior = {
  sub: Infer({
    model: function(){ return categorical({vs: stateVals, ps: stateProbs.sub}) }
  }),
  super: Infer({
    model: function(){ return categorical({ vs: stateVals, ps: stateProbs.super}) }
  })
};
'
```

```{r rsaLanguage}
languageForRSA <- '
var thresholdBins ={
  positive: map(function(x){
    return  x - (1/(binParam*2));
  }, sort(statePrior.super.support())),
  negative: map(function(x){
    return  x + (1/(binParam*2));
  }, sort(statePrior.super.support()))
};

var thresholdPrior = cache(function(form){
  return Infer({
    model: function() { return uniformDraw(thresholdBins[form]) }
  });
});

var utterances = {
  positive: ["positive_Adjective",
             "silence_silence",
             "positive_sub",
             "positive_super"],
  negative: ["negative_Adjective",
             "silence_silence",
             "negative_sub",
             "negative_super"]
};

// explicit comparison class is twice as expensive; silence is cheap
var utteranceProbs = [1, 1, 1, 1];
// uniform costs
// var utteranceCosts = [1, 1, 1, 1, 1, 1, 1];
// var utteranceProbs = map(function(c) {return exp(-c)}, utteranceCosts);
var utterancePrior = cache(function(form){
  return Infer({
    model: function() {
      return categorical({
        vs: utterances[form],
        ps: utteranceProbs
      })
    }
  })
});

var meaning = function(utterance, state, thresholds) {
  utterance == "positive" ? state > thresholds.positive ? flip(0.9999) : flip(0.0001) :
  utterance == "negative" ? state < thresholds.negative ? flip(0.9999) : flip(0.0001) :
  true
}

'
```

```{r ccRSA}
ccrsa <- '
// webppl ccrsa.wppl --require adjectiveRSA
var classPrior = Infer({
  model: function(){return uniformDraw(["sub", "super"])}
});

var alphas = {s1: 10, s2: 1};

var literalListener = cache(function(u, thresholds, comparisonClass) {
  Infer({model: function(){
    var cc = u.split("_")[1] == "Adjective" ?
        comparisonClass :
    u.split("_")[1] == "silence" ?
        comparisonClass :
    u.split("_")[1]    

    var state = sample(statePrior[cc]);
    var utterance = u.split("_")[0]
    var m = meaning(utterance, state, thresholds);
    condition(m);
    return state;
  }})
}, 10000)

var speaker1 = cache(function(state, thresholds, comparisonClass, form) {
  Infer({model: function(){
    var utterance = sample(utterancePrior(form))
    var L0 = literalListener(utterance, thresholds, comparisonClass)
    factor( alphas.s1 * L0.score(state) )
    return utterance
  }})
}, 10000)

var pragmaticListener = function(form) {
  Infer({model: function(){
    var utterance = form + "_Adjective";
    var comparisonClass = sample(classPrior);
    var state = sample(statePrior["sub"]);
    var thresholds = form == "positive" ? {
      positive: sample(thresholdPrior("positive"))
    } : {
      negative: sample(thresholdPrior("negative"))
    }
    var S1 = speaker1(state, thresholds, comparisonClass, form);
    observe(S1, utterance);
    return comparisonClass
  }})
}

pragmaticListener(paramsFromR.utt[0])
'
```

```{r runModel, cache = T}


sub.prior.params <- c( 
  list( sub = data.frame(mu = 1, sigma = 0.5) ),
   list( sub = data.frame(mu = 0, sigma = 0.5) ),
   list( sub = data.frame(mu = -1, sigma = 0.5) )
  )

mp.both <- data.frame()

fullModel <- paste(webpplHelpers, priorForRSA, languageForRSA, ccrsa, sep = "\n")

for (p in sub.prior.params){
  prior.params <- list(super = data.frame(mu = 0, sigma = 1), sub = p)

  for (u in c("positive", "negative")){
  
    mp <- webppl(
      program_code = fullModel,
      data = list(utt = u, priorParams = prior.params),
      data_var = "paramsFromR"
    )

    mp.both <- bind_rows(mp %>%
      filter(support == "super") %>%
      mutate(u = u, sub_mu = p["mu"][[1]], sub_sigma = p["sigma"][[1]]),
      mp.both)
  }
  #print(p$mu)
}

```

```{r priorModel, cache = T}
priorModel <- "
var stateParams = {
  sub: priorParamsFromR.sub[0],
  super: priorParamsFromR.super[0]
};

var priorModel = function(){
  var subcat = gaussian(stateParams.sub);
  var supercat = gaussian(stateParams.super);
  return {subcat, supercat}
}

var prior = Infer({method: 'forward', samples: 10000, model: priorModel})
prior
"
all.priors <- data.frame()
for (p in sub.prior.params){
  prior.params <- list(super = data.frame(mu = 0, sigma = 1), sub = p)

  prior.samples <- webppl(priorModel,
                          data = prior.params,
                          data_var = "priorParamsFromR")

  prior.tidy <- prior.samples %>%
    rename(subordinate = value.subcat, superordinate = value.supercat) %>%
    gather(key, val) %>%
    mutate(class = factor(key, levels = c( "superordinate", "subordinate")),
           sub_mu = p["mu"][[1]], sub_sigma = p["sigma"][[1]])
  
  all.priors <- bind_rows(all.priors, prior.tidy)
  #print(p$mu)
}
```

```{r modelSchematics, fig.env = "figure", fig.pos = "htb", fig.width=3.3, fig.height=3, fig.cap = "Left: Three schematic prior distributions over subordinate comparison class (fixing the superordinate comparison class to be a unit-normal distribution). Right: Predicted listener inference for the probability of an intended subordinate comparison class. Model prediction assume an alpha of 3 and a cost of 2 for the explicit comparison class alternatives. The comparison class prior does not favor either the subordinate or superordinate class."}

subplt1 <- ggplot(all.priors, aes(x = val, y=..scaled.., 
                                  fill = factor(sub_mu), 
                                  lty = class, group= factor(sub_mu)))+
  geom_density(alpha = 0.8)+
  #scale_fill_brewer(palette = "Set2") +
  #scale_fill_gry()+
  #guides(fill = F)+
  ggtitle("Priors on degree")+
  xlab("Degree")+
  ylab("Scaled probability")+
  #facet_wrap(~sub_mu, nrow = 1)+
  # theme(title = element_text(size = 8),
  #       legend.text = element_text(size = 6),
  #       axis.text = element_text(size = 6))+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  scale_x_continuous(limits = c(-4, 4), breaks = c(-2, 0, 2))


subplt2 <- ggplot(mp.both %>%
                    mutate(Adjective = factor(u,
                                      levels = c("negative", "positive"))),
                  aes(x = sub_mu, y = prob, fill = Adjective))+
  geom_bar(stat= 'identity', position = position_dodge(), color = 'black', alpha = 0.8, width = 0.5)+
  scale_fill_brewer(palette = "Set3")+
  geom_hline(yintercept = 0.5, lty = 3)+
  xlab("Subordinate prior mean")+
  ylab("Superordinate interpretation")+
  ggtitle("RSA listener model") +
  # theme(title = element_text(size = 8),
  #       legend.text = element_text(size = 6))+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))

grid.arrange(subplt1, subplt2, nrow = 2)
```


<!--
In this paper, we argue that pragmatic principles can be used to resolve the comparison class in context.
We extend the Rational Speech Act theory of @Lassiter2013 to include uncertainty over the comparison class.
We test this model in a simplified setting, where the comparison class could either be a subordinate or superordinate class (e.g., toasters vs. kitchen appliances).
In this simplified setting, we find the model predicts the level of abstraction (sub vs. superordinate) of a comparison class depends upon the quantitative details of the relevant prior beliefs (e.g., the prices of toasters vs. the prices of kitchen appliances in general).
We test this prediction using a paraphrase experiment (Expt. 1).
Quantitative predictions for Bayesian models (including this one) depend upon the quantitative details of listeners' prior distributions over various scales.
Because it may be difficult for human participants to estimate quantities accurately, we introduce a novel Bayesian data-analytic technique for learning about listeners' prior belief distributions using convergent language understanding tasks.
-->

We elaborate the Rational Speech Act theory for vague language understanding [@Lassiter2013; @Lassiter2015] by introducing uncertainty over the class of entities against which the target entity is compared --- the comparison class $c$.
We posit that pragmatic language interpretaion involves reasoning about the likely reference class.
In addition to the uncertainty over the comparison class $c$, a pragmatic listener also has uncertainty over the value of the degree $x$ (e.g., the temperature of the day) and the semantic threshold variable $\theta$ as in @Lassiter2013.
Uncertainty about the value of the degree $x$ is always with respect to a comparison class $c$: $P(x \mid c)$.


```{r echo = F, eval =F, results = "asis", fig.env = "table*", fig.pos = "b", fig.width = 4, fig.height = 2, fig.align = "center", set.cap.width = T, num.cols.cap = 2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}

height_sub = c("professional basketball player, professional gymnast, professional soccer player")
height_super = c("people")
price_sub = c("dishwasher, oven, toaster")
price_super = c("kitchen appliances")
temperature_sub = c("Fall in Maryland, Summer in Maryland, Winter in Maryland")
temperature_super = c("days of the year in Maryland")
time_sub = c("video of a cute animal, music video, movie")
time_super = c("things you watch online")
weight_sub = c("apple, grape, watermelon")
weight_super = c("produce")

scales = c("Height", "Price", "Temperature", "Time", "Weight")
sub = c(height_sub, price_sub, temperature_sub, time_sub, weight_sub)
super = c(height_super, price_super, temperature_super, time_super, weight_super)

table1 = data.frame(Scale = scales, Subordinate = sub, Superordinate = super)
table1 <- xtable(table1)
print(table1, type = "latex", include.rownames = FALSE, tabular.environment = "tabularx", width = "\\textwidth", floating.environment = "table*")
```

\begin{table*}
\centering
\begin{tabular}{lll}
  \hline
Scale \{\emph{adjectives}\}& Subordinate & Superordinate \\
  \hline
Height \{\emph{tall}, \emph{short}\} & professional \{basketball player, soccer player, gymnast\} & people \\
  Price \{\emph{expensive}, \emph{cheap}\}& \{dishwasher, toaster, oven\} & kitchen appliances \\
  Temperature \{\emph{warm}, \emph{cold}\}& \{Summer, Fall, Winter\} day in Maryland & days of the year \\
  Time \{\emph{long}, \emph{short}\}& \{movie, music video, video of a cute animal\}  & things you watch online \\
  Weight \{\emph{heavy}, \emph{light}\}& \{watermelon, grape, apple\}  & produce \\
   \hline
\end{tabular}
\caption{Items used in experiments}
\label{tab:1}
\end{table*}


```{r, eval = F, echo=F}
## simulations to determine width of 95% CI for 2AFC data assuming different sample sizes and true binomial probabilities

### not written efficiently... will take ~10 minutes to run
n_participants <- c(50, 75, 100)
true_probs <- c(0.1, 0.3, 0.5)
simulations <- data.frame()
for (n in n_participants){
  for (p in true_probs){
    for (i in seq(1, 25)){
      simulations <- bind_rows(simulations,
            bind_rows(data.frame(label = c("a"),
                       response = rbinom(n =n, size = 1, prob = p)),
                data.frame(label = c("b"),
                           response = rbinom(n =n, size = 1, prob = p))) %>%
            group_by(label) %>%
            multi_boot_standard(column = "response") %>%
            mutate(width = ci_upper - ci_lower) %>%
          ungroup() %>%
          summarize(w = mean(width)) %>%
            mutate(n = n, p = p, i=i)
      )
    }
  }
}

ggplot(simulations, aes(x = w))+
 geom_histogram()+
 facet_grid(n~p)

```

```{r cache=T}
data.path <- paste(project.path, "data/classElicitation-1/", sep = "")

d.catch <- read.csv(paste(data.path, "class-elicitation-full-catch_trials.csv", sep = ""))
d.catch <- d.catch %>%
  mutate(pass = response == "relative to other buildings") %>%
  select(workerid, pass)

d <- read.csv(paste(data.path, "class-elicitation-full-trials.csv", sep = ""))
d.tidy <- left_join(d, d.catch) %>%
  filter(pass) %>%
  mutate(superResponse = ifelse(paraphrase == "super", 1, 0))

df.summary <- d.tidy %>%
  group_by(strength, target, degree, adjective, form, sub_category, super_category) %>%
#  group_by(condition, strength, target, degree, adjective, form, sub_category, super_category) %>%
  multi_boot_standard(column = "superResponse")
```


```{r, cache = T}
project.name <- "vague-prior-elicitation-1"
data.path <- paste(project.path, "data/vagueSpeaker-1/", sep = "")
d.catch <- read.csv(paste(data.path, project.name, "-catch_trials.csv", sep = ""))
d.catch <- d.catch %>% 
  mutate(pass = response == "Yes")

d <- read.csv(paste(data.path, project.name, "-trials.csv", sep = ""))

vs.summary <- left_join(d, d.catch %>% select(workerid, pass)) %>%
  filter(pass) %>%
  group_by(strength, target, degree, adjective, 
           form, sub_category, super_category) %>%
  multi_boot_standard(column = "response")

```

```{r expt1results, fig.env = "figure*", fig.pos = "htb", fig.width=6.6, fig.height=3.75, fig.align='center', set.cap.width=T, num.cols.cap=2, fig.cap = "Empirical data. Top: Experiment 1 results. Comparison class judgments in terms of proportion judgments in favor of superordinate comparison class. Bottom: Experiment 2 results. Adjective endorsement given knowledge of  subordinate membership, with the superordinate category as the explicit comparison class. Error bars correspond to bootstrapped 95 percent confidence intervals."}

bind_rows(
  df.summary %>%
    ungroup() %>%
    mutate(experiment = 'Comparison class inference'),
  vs.summary %>%
    ungroup() %>%
    mutate(experiment = 'Adjective production')
) %>%
  mutate(sub_category = 
           factor(sub_category, 
                  levels = sub_category[order(strength)]),
         experiment = factor(experiment, levels = c('Comparison class inference',
                                                    'Adjective production'))
          # condition = factor(condition, levels = c("context","contextWithSuper"),
          #                    labels=c("Bare", "Supercat mention"))
         ) %>%
  ggplot(.,
         aes( x = sub_category, y = mean, 
              ymin = ci_lower, ymax = ci_upper, 
              group = form, fill = form ) )+
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 1, 
           color = 'black', width = 0.9) +
  geom_errorbar(position = position_dodge(0.9), width = 0.3) +
  #facet_grid(condition~degree, scales = 'free') +
  facet_grid(experiment~degree, scales = 'free') +
  ylim(0, 1) +
  #theme(axis.text.x = element_text(angle = 90, hjust = 0.95) ) +
  scale_fill_brewer(palette = 'Set3') +
  ylab("Proportion superordinate paraphrase") +
  xlab("Item category") +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.95))
  # theme(axis.title.y = element_text(size = 10),
  #       strip.text = element_text(size = 8))



# 
#     mutate(sub_category = factor(sub_category, levels = sub_category[order(strength)])) %>%
#   ggplot(.,
#          aes( x = sub_category, y = mean, ymin = ci_lower, ymax = ci_upper, group = form, fill = form ) )+
#   geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.8)+
#   geom_errorbar(position = position_dodge())+
#   facet_grid(.~degree, scales = 'free')+
#   ylim(0, 1) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 0.95))+
#   scale_fill_brewer(palette = 'Set1')+
#   ylab("Superordinate adjective endorsement")+
#   xlab("Item category")#+
#   # theme(axis.title.y = element_text(size = 10),
#   #       strip.text = element_text(size = 8))
```


As a first test of this idea, we consider a simplified case where the comparison class can either be a relatively subordinate or superordinate categorization (e.g., *warm* relative to days in Winter or relative to all days of the year). 
The listener is aware that the target entity is a member of the subordinate class (e.g., aware that it is winter) and draws likely values of the degree from the subordinate class prior: $P(x \mid c_{sub}$.
<!---->
\begin{align}
L_{1}(x, c, \theta \mid u) &\propto S_{1}(u \mid x, c, \theta) \cdot P(x \mid c_{sub}) \cdot P(c) \cdot P(\theta) \label{eq:L1}
\end{align}
<!---->
The listener believes the speaker had some intended comparison class in mind, as well as some degree he was trying to communicate and some threshold he was using: $S_{1}(u \mid x, c, \theta)$.
The speaker's utility function is a standard information-theoretic utility in which the speaker gains higher utility by decreasing a *literal listener*'s surprisal [@Goodman2013].
The speaker is assumed to be soft-max rational with degree of rationality governed by $\alpha_1$. 
<!---->
\begin{align}
S_{1}(u \mid x, c, \theta) &\propto \exp{(\alpha_1 \cdot [\ln {L_{0}(x \mid u, c, \theta)} - \text{cost}(u)])} \label{eq:S1}\\
L_{0}(x \mid u, c, \theta) &\propto {\delta_{[[u]](x, \theta)} \cdot P(x \mid c)}. \label{eq:L0}
\end{align}
<!---->
In addition, the speaker has a cost function associated with the relative complexity of alternative utterances $\text{cost}(u)$.
We use a speaker model that considers the alternatives of using the same utterance with the explicit comparison class (e.g., "It is warm relative to other days in Winter.", "It is warm relative to other days of the year.") as well as the alernative of remaining silent (a null utterance with no informational content).
For simplicity of the model, we assume each utterance has equal cost.
We are interested in the behavior of the model with the underspecified utterance (e.g., "It is warm").
<!--
When the pragmatic listener hears this utterance, she must reason about which comparison class the speaker had in mind.
When the speaker produces the unambiguous alterantive utterance (e.g., "It is relative to other days in Winter."), the listener 
-->
In the following section, we explore the predictions of this model.

## Model predictions

As a first test of this pragmatic theory, we consider a simple case:
The comparison class is either a subordinate level category (e.g., days in Winter) or a superordinate level category (e.g., days of the year).
For purposes of illustration, we assume each class is equally likely *a prior*: $c \sim \text{UniformDraw}([c_{sub}, c_{super}])$.
We also assume the listener $L_1$ knows the target entity is a member of the subordinate class (e.g., knows that it's Winter): $P(x \mid c_{sub})$.
Then, the listener $L_1$ tries to uncover the speaker's implicit comparison class $c$ by incorparting what she knows about the subordinate level category (e.g., temperature of days in winter) $P(x \mid c_{sub})$ and the superordinate level category (e.g., temperature of days in general) $P(x \mid c_{super})$.

The likely comparison class will depend on the details of the prior distributions over the sub- and superordinate level classes (e.g., listener's subjective degrees of belief in various temperatures) as well as the polarity of the gradable adjective (i.e., *tall* vs. *short*).
For simplicity, we assume the prior distribution over the degree for the superordinate class is a unit-normal distribution $x_{super} \sim \mathcal{N}(0, 1)$ and explore the model predictions as we vary the mean and standard deviation for the prior of the subordinate class.
<!--
Model schematic. Show "John is tall for a person", "John is tall for a baskebatll player", "John is tall."
-->

Consider the three subordinate priors to correspond to temperatures in Winter (-1), Fall (0), and Summer (1) in a part of the world that exhibits seasons (e.g., Maryland, USA), and the superordinate prior to correspond to temperatures including all days of the year (Figure \ref{fig:modelSchematics}, left).
We see that regardless of the adjective form (positive or negative) or the mean of the prior distribution (-1, 0, 1), the pragmatic listener prefers the more specific comparison class (i.e., the subordinate class; Figure \ref{fig:modelSchematics}, right).
Note that the only thing differentiating the subordinate from the superordinate class is the variance.
<!--This comes from the vagueness of adjectives: The meaning of the adjective in context depends upon the prior; a prior with less variance will result in a relatively more precise meaning.-->
We also see that when the pragmatic listener (Eq. \ref{eq:L1}) is in Winter and hears that "It's warm" (positive adjective), she thinks it's more likely that it's warm relative to days in Winter than when she hear's it's cold (Figure \ref{fig:modelSchematics}, right, left-most facet; compare blue vs. red bars).
The model thinks the opposite is true in Summer: A warm day in summer could be warm for summer, or warm for the year, while a cold day in Summer is much more likely to be cold for summer.
In sum, we see two predictions: The pragmatic listener overall prefers subordinate comparison classes, though the extent of this preference is modulated by the relationship of the subordinate to the superordinate class prior.
<!--
We see that as the mean of the subordinate prior becomes greater than the superordinate prior, positive form adjectives (e.g., *tall*, *expensive*, *warm*) will be more likely to imply a superordinate comparison class (e.g., *people in general*), while negative form adjectives (e.g., *short*, *cheap*, *cold*) will imply a subordinate class (e.g., *basketball players*).
The opposite pattern is observed for subordinates priors with a mean substantially lower than the superordinate prior.
We test these predictions in our first experiment.
-->

# Experiment 1: Comparison class inference

In this experiment, we test whether the level of abstractness of the comparison class \textit{c} (subordinate vs. superordinate category) depends upon the subordinate category that target entity is a member of.

## Methods

### Participants

<!--
Note: We are collecting N = 150 for each experiment. Because each participant reads have of the prompts, we expect about n = 75 per item. Simulations reveal that with n = 75, a 95% CI will have maximum width of about 0.2 - 0.25. Note that maximum width occurs when true probability is 0.5.
-->

We recruited 264 participants from Amazon Mechanical Turk.
Two participants were excluded for failing an attention check, leaving a total number of 262 participants.
Participation was restricted to those with U.S. IP addresses and who had at least a 95% work approval rating.
The experiment took about five minutes and participants were compensated $0.50 for their work.


### Materials

We tested our hypothesis using positive- and negative-form gradable adjectives describing five scales: price (*expensive*, *cheap*), temperature (*warm*, *cold*), duration (*long*, *short*), height (*tall*, *short*), and weight (*heavy*, *light*).
Each scale was paired with a superordinate category: kitchen appliances (price), weather throughout the year (temperature), things you watch online (duration), people (height), and produce (weight).
For each superordinate category, we used three subordinate categories that aimed to be situated near the high-end, low-end, and intermediate part of the degree scale (as in Model Prediction section).
This resulted in 30 unique events (\{3 subordinate categories\} x \{5 scales\} x \{2 adjective forms\}; see Table \ref{tab:1} for full listing).

### Procedure

Each participant saw 15 trials: one for each subordinate category paired with either the positive or negative form of its corresponding adjective.
On each trial, participants were given a context sentence to introduce the subordinate category (e.g., *Tanya lives in Maryland and steps outside in Winter.*).
This was followed by an adjective sentence, which predicated either a positive- or negative-form gradable adjective over the item (e.g., *Tanya says to her friend, "It's warm."*).
Participants were asked "What do you think Tanya meant?" and given two options to rephrase the adjective sentence with an explicit comparison class of either the subordinate or superordinate category: 

\begin{itemize}
\item \{She / He / It\} is \textsc{adjective} relative to other \textsc{subordinates} (e.g., \emph{It's warm relative to other days in Winter})
\item \{She / He / It\} is \textsc{adjective} relative to other \textsc{superordinates} (e.g., \emph{It's warm relative to other days of the year})
\end{itemize}

Participants never judged the same subordinate category for both adjective forms (e.g., cold and warm Winter days) and back-to-back trials involved different scales to avoid fatigue.
In addition to all of the above design parameters, half of participants completed trials where an additional sentence introduced the superordinate category at the beginning (e.g., *Tanya lives in Maryland and checks the weather every day.*), with the intention of making the superordinate paraphrase more likely. 
The experiment can be viewed in full at:
\url{http://stanford.edu/~mtessler/comparison-class/experiments/class-elicitation-2afc.html}

## Results

```{r glm1, cache = T}
d.centered = d.tidy %>%
                   filter(!(strength == 2)) %>%
                   mutate(strength = ifelse(strength == 3, 1, 
                                            ifelse(strength == 1, 0,
                                                   -99)),
                          c.strength = strength-mean(strength),
                          num.form = as.numeric(form) - 1,
                          c.form = num.form - mean(num.form))

# with interaction random effects
rs.glmm <- glmer(data = d.centered, 
                 superResponse ~ c.form*c.strength +
                   (1 + c.form:c.strength | sub_category) +
                   (1 | workerid),
                 family = 'binomial')
rs.glmm.summary <-  summary(rs.glmm)
 
#simple effect model doesn't converge w/ interaction random effects
d.centered$strength = as.factor(d.centered$strength)
rs.glmm.simple <- glmer(data = d.centered, 
                 superResponse ~ strength*form - form +
                   (1  | sub_category) +
                   (1  | workerid),                   
                 family = 'binomial')
rs.glmm.simple.summary <- summary(rs.glmm.simple)



```

On each trial, the participant was given an utterance with a gradable adjective and asked which comparison class (subordinate vs. superordinate) the speaker meant.
We observe no systematic differences between participants' responses when the superordinate category was explicitly mentioned previously in the context and those when it was not; thus we collapse across these two conditions for the rest of this paper.
Figure \ref{fig:expt1results} shows the proportion of participants choosing the subordinate category for each item.
We see considerable variability both within- and across- scales.
Within each scale, we see the predicted interaction: For items that are expected to fall high on the scale (basketball players, watermelons, Summer days, dishwashers, movies), positive form adjectives tend to elicit superordinate comparison classes while negative form adjectives tend to elicit subordinate comparison classes (i.e., a basketball player is *tall* relative to other people, but *short* relative to the basketball players).
For items that are expected to fall low on the scale (gymnasts, grapes, Winter days, bottle openers, videos of cute animals), the opposite effect is observed (i.e., a video of a cute animal is *short* relative to other things you watch online, but *long* relative to other videos of cute animals).

This is confirmed using a generalized linear mixed effects model with main effects of adjective form (positive vs. negative) and the *a priori* judgment by the first author of the relative position on the scale of the sub-category (i.e., sub-category item expected to be low or high), and of critical theoretical interest, the interaction between these two variables
In addition, we included in the model by-participant random effects of intercept and by-subordinate category random effects of intercept and the iteraction between form and strength to predict the probability with which participants would choose the superordinate category as the paraphrase^[
This was the maximal mixed-effects structure that converged.
].
Confirming our two qualitative model predictions, there was an overall preference for subordinate category paraphrases ($\beta = `r round(rs.glmm.summary[["coefficients"]]["(Intercept)","Estimate"],2)`$;
$SE = `r round(rs.glmm.summary[["coefficients"]]["(Intercept)","Std. Error"],2)`;$
$z = `r round(rs.glmm.summary[["coefficients"]]["(Intercept)","z value"],2)`$) and there was an interaction between form and strength 
($\beta = `r round(rs.glmm.summary[["coefficients"]]["c.form:c.strength","Estimate"],2)`$;
$SE = `r round(rs.glmm.summary[["coefficients"]]["c.form:c.strength","Std. Error"],2)`;$
$z = `r round(rs.glmm.summary[["coefficients"]]["c.form:c.strength","z value"],2)`$).
The main effects of form and strength were not significant.

Following up on this model, we examine the simple effects of strength for both positive and negative form adjectives.
We find the predicted effects on superordinate paraphrase probability for items both on the low and high end of the scale. 
For items on the low end of the scale (e.g., Winter days on temperature), positive form adjectives are significantly more likely to lead *away* from superordinate comparison classes (
$\beta = `r round(rs.glmm.simple.summary[["coefficients"]]["strength0:formpositive","Estimate"],2)`$;
$SE = `r round(rs.glmm.simple.summary[["coefficients"]]["strength0:formpositive","Std. Error"],2)`;$
$z = `r round(rs.glmm.simple.summary[["coefficients"]]["strength0:formpositive","z value"],2)`$), while the opposite is true for items on the high end of the scale (e.g., Summer days; 
$\beta = `r round(rs.glmm.simple.summary[["coefficients"]]["strength1:formpositive","Estimate"],2)`$;
$SE = `r round(rs.glmm.simple.summary[["coefficients"]]["strength1:formpositive","Std. Error"],2)`;$
$z = `r round(rs.glmm.simple.summary[["coefficients"]]["strength1:formpositive","z value"],2)`$).
All of these effects are also visually apparent in Figure \ref{fig:expt1results}.


The two qualitative predictions of our language understanding model were borne out in Experiment 1.
Our computational model makes quantitative predictions as well, though these will depend on the quantitative details of the pragmatic listener's world knowledge.
This world knowledge is often measured by having participants estimate relevant quantities assuming only what would be available prior to the linguistic phenomenon of interest [e.g., the temperature in Maryland on a day in Winter; @FrankeEtAl2016].
These quantities can be difficult to estimate, however, especially for abstract superordinate quantities (e.g., the temperature in Maryland on a day of the year).

In the next section, we formalize our uncertainty about listeners' prior knowledge, and run a second experiment to gather converging evidence about listeners' knowledge, which we can then use to generate quantitative predictions for Expt. 1.

# Reducing uncertainty in prior knowledge by asking follow-up questions

Bayesian models of cognition and language strongly rely upon accurate measurement of prior knowledge [@FrankeEtAl2016].
For models of language understanding, prior elicitation tasks typically take the form of running the same language understanding task but removing the target utterance that is aimed to be model [e.g., @Kao2014]. 
Certain quantities and probabilities are inherent difficult measure because they are abstract or hard to estimate.
In previous work, we have attempted to measure prior knowledge by decomposing what would be a single, complicated question into two simpler questions, and then using a Bayesian data analytic approach to reconstruct the prior knowledge [@Tessler2016; @Tessler2016cogsci].
Here, we extend this to ask *natural language* questions that use the same prior knowledge as would be relevant for Expt.~1 and which a reduced form of computational model presented in this paper can answer.
This has the feature of reducing task demand on participants.

As we did for the simulations presented before, we assume the superordinate prior is a unit-normal distribution. 
We assume the subordinate priors also are normal distributions, but with unknown parameters $\mu_{sub}, \sigma_{sub}$.
We can wrap the RSA model presented earlier inside a Bayesian data analysis model and infer these parameters likely values.
Using just the data from Expt.~1, this model would be overparametrized.
We can make a subtle modification of the RSA model to ask follow-up questions that would rely upon the same prior knowledge. 
In particular, we will ask participants that assuming a target entity is a member of the subordinate (e.g., it's a day in Winter), would they predict the adjective would apply with an explicit comparison class (e.g., "Is it warm relative to other days of the year?").

This is a simplification of the comparison class inference model because it eliminates the uncertainty in the relevant comparison class.
Since this question is a felicity-judgment, we model this as a pragmatic speaker [@Qing2014a; @Tessler2016; @Tessler2016cogsci]
\begin{align}
S_{2}(u \mid c_{sub}) &\propto \exp{(\alpha_2 \cdot \ln{L_1(x, \theta \mid u, c_{super})})} \label{eq:S2} \\
L_{1}(x, \theta \mid u, c_{super}) &\propto S_{1}(u \mid x, c_{super}, \theta) \cdot P(x \mid c_{sub}) \cdot P(\theta) \label{eq:L1a}
\end{align}

We use Eq.~\ref{eq:S2} to model adjective production data in Experiment 2 (described below). 
We use Eq.~\ref{eq:L1} to model the comparison class inference task of Experiment 2. 
Following @Lassiter2013, $P(\theta) = \text{Uniform}(0, 1)$.

$P(c)$ describes the prior probability of the superordinate (or subordinate) comparison class used by the listener in the comparison class inference model (and Expt.~1). 
This is likely specified by conceptual knowledge and will heavily be influenced by the subordinate and superordinate items we designed (Table \ref{tab:1}).
This prior in itself is of major theoretical interest and future work should attempt to understand the differences in our items that would lead to different $P(c)$. 
<!--In an absolute sense, this is the real target of theoretical interest. -->
In this work, we are interested in a within-domain effect (i.e., the variability within the domain of daytime temperatures).\footnote{
That is, fixing some prescribed set of potential comparison classes, what is a listener likely to infer is the relevant one. \mht{should come earlier and probably not in a footnote}
}
Hence, in our data analysis, we put uncertainty over the prior probability of each of the 5 $i$ superordinate categories: $c^{super}_{i} \sim \text{Uniform}(0,1)$
\mht{If we keep the domain-wise ccPrior variable, need to square this with the "main effect of subordinate" that I say we're predicted.}

\usetikzlibrary{bayesnet}
\begin{figure}[ht]
\begin{center}
\begin{tikzpicture}

\node[latent, minimum size=1cm, ] (L0_speaker) {$L_{0}$} ;
\node[latent, minimum size=1cm, below=of L0_speaker] (S1_speaker) {$S_{1}$} ;
\node[latent, minimum size=1cm, below=of S1_speaker] (L1_speaker) {$L_{1}$} ;
\node[latent, minimum size=1cm, below=of L1_speaker] (S2_speaker) {$S_{2}$} ;

\node[latent, minimum size=1cm, left=of S1_speaker] (alpha_1) {$\alpha_1$} ;
\node[obs, minimum size=1cm, right=of L1_speaker] (comparison_class) {$d_{\text{Expt 1}}$} ;
\node[latent, minimum size=1cm, left=of S2_speaker] (alpha_2) {$\alpha_2$} ;
\node[obs, minimum size=1cm, right=of S2_speaker] (utterance) {$d_{\text{Expt 2}}$} ;  

\node[latent, minimum size=1cm, right=of L0_speaker] (comparison_class_prior) {$x | c_{sub}$} ;

\node[latent, minimum size=1cm, right=of comparison_class_prior, yshift=0.6cm] (mu) {$\mu_{sub}$} ;
\node[latent, minimum size=1cm, right=of comparison_class_prior, yshift=-0.6cm] (sigma) {$\sigma_{sub}$} ;

\edge {L0_speaker} {S1_speaker} ;
\edge {S1_speaker} {L1_speaker} ;
\edge {L1_speaker} {S2_speaker} ;

\edge {alpha_1} {S1_speaker} ;
\edge {L1_speaker} {comparison_class} ;
\edge {alpha_2} {S2_speaker} ;
\edge {S2_speaker} {utterance} ;

\edge {comparison_class_prior} {L0_speaker} ;
\edge {comparison_class_prior} {L1_speaker} ;

\edge {mu} {comparison_class_prior} ;
\edge {sigma} {comparison_class_prior} ;

\plate {} {
	(L0_speaker)(S1_speaker)(L1_speaker)(S2_speaker)
} {RSA}

\plate {} {
	(mu)(sigma)(comparison_class_prior)
} {$\forall sub \in \mathcal{S}$}

\end{tikzpicture}
\end{center}
\caption{RSA and data analysis model. The recursive Bayesian RSA model is visualized in the center block. $L_1$ is used as a model for Experiment 1 data and  $S_2$ for Experiment 2 data. The subordinate category priors $P(x \mid c_{sub})$ are used in both experiments and are modeled as Gaussians with unknown mean and variance.)}
\end{figure}

Instead, we ask similar questions in the same domains to a separate set of participants, and use the data from both experiments to gain more certainty about the relevant prior knowledge.


We take a different approach. 
We assume a simple functional form to the prior and infer the likely parameter values of those priors from the data and our language model.
This by itself simply adds extra parameters to the model, and we wouldn't know if the "prior knowledge" we're learning would generalize to other tasks that require the same knowledge. 
To alleviate this problem of overfitting, we run a second experiment with the same language model as our guide. 
We ask similar questions in the same domains, and use the data from both experiments to gain more certainty about the relevant prior knowledge.

# Experiment 2: Adjective production

In this experiment, we use a two-alternative forced choice paradigm to collect speaker judgments using the same language model as before.

## Methods

### Participants

We recruited 100 participants from Amazon Mechanical Turk.
Five participants were excluded due to failing the catch trial.
Participation was restricted to those with U.S. IP addresses and who had at least a 95% work approval rating.
On average, the experiment took five minutes and participants were compensated $0.50 for their work. 

### Materials, procedure, and results

Materials were the same as Expt. 1 (Table 1).

Each participant saw 15 trials: one for each subordinate category paired with either the positive or negative form of its corresponding adjective.
On each trial, participants were given a sentence introducing the subordinate category (e.g., *Alicia lives in Maryland and steps outside in Winter.*).
This was followed by a target sentence, which predicated a positive- or negative-form adjective over the superordinate category of the item (e.g., *Do you think the day in Winter would be warm relative to other days of the year?*).
As in Expt.~1, participants never rated the same subordinate category for both adjective forms and back-to-back trials involved different scales to avoid fatigue.
The experiment can be viewed in full at: 
\url{http://stanford.edu/~mtessler/comparison-class/experiments/vague-prior-elicitation-2afc.html}

The results of this experiment can be seen in Figure \ref{expt1results} (bottom). 
We see that the endorsement of adjectival phrases in these domains is markedly more categorical than the comparison class inference task.
In the last section, we formalize our uncertainty about listeners' prior knowledge for these experiments to generate quantitative model predictions for the two data sets.

# Inferring prior knowledge and quantitative model predictions 

Bayesian models of cognition and language strongly rely upon accurate measurement of prior knowledge [@FrankeEtAl2016].
For models of language understanding, prior elicitation tasks typically take the form of running the same language understanding task but removing the target utterance that is aimed to be model [e.g., @Kao2014]. 
Certain quantities and probabilities are inherently difficult to measure because they are abstract or hard to estimate.
In previous work, we have attempted to measure prior knowledge by decomposing what would be a single, complicated question into two simpler questions, and then using a Bayesian data analytic model to reconstruct the prior knowledge [@Tessler2016; @Tessler2016cogsci].
Here, we extend this to ask *natural language* questions that use the same prior knowledge as would be relevant for Expt.~1 and which can be interpreted by the same language model.
This has the feature of reducing task demand on participants.

As we did for the simulations presented before, we assume the superordinate prior is a unit-normal distribution. 
We assume the subordinate priors also are normal distributions, but with unknown parameters $\mu_{sub}, \sigma_{sub}$.
We build a Bayesian data analysis model on top of the RSA model presented earlier and infer these parameters likely values.
Using just the data from Expt.~1, this model would be overparametrized \mht{what do i want to say here?},
but we can ask related questions in the same domains and use the RSA model to predict those as well
. 
In particular, we will ask participants that assuming a target entity is a member of the subordinate (e.g., it's a day in Winter), would they predict the adjective would apply with an explicit comparison class (e.g., "Is it warm relative to other days of the year?").
This is a simplification of the comparison class inference model because it eliminates the uncertainty in the relevant comparison class.
Since this question is a felicity-judgment, we model this as a pragmatic speaker [@Qing2014a; @Tessler2016; @Tessler2016cogsci]
\mht{In this model, I use a KL-speaker (rather than the usual factor based on the true state of the world speaker). is that math different?}
<!---->
\begin{align}
S_{2}(u \mid c_{sub}) &\propto \exp{(\alpha_2 \cdot \ln{L_1(x, \theta \mid u, c_{super})})} \label{eq:S2} \\
L_{1}(x, \theta \mid u, c_{super}) &\propto S_{1}(u \mid x, c_{super}, \theta) \cdot P(x \mid c_{sub}) \cdot P(\theta) \label{eq:L1a}
\end{align}
<!---->
We use Eq.~\ref{eq:S2} to model adjective production data in Experiment 2. 
We use Eq.~\ref{eq:L1} to model the comparison class inference task of Experiment 2. 
Following @Lassiter2013, $P(\theta) = \text{Uniform}(0, 1)$.

### Empirical prior on comparison classes

$P(c)$ describes the prior probability of the superordinate (or subordinate) comparison class used by the listener in the comparison class inference model (and Expt.~1). 
We posit that $P(c)$ reflects listeners' expectations about the likely completions of the (otherwise incomplete) adjective sentence (e.g., "It's warm relative to other $c$").
If this is so, we would expect $P(c)$ to be correlated with factors relevant for speech production, e.g., the frequency of the comparison class. 
We adopt log-frequency as our proxy, which we estimate using the Google Web Gram corpus^[
Corpus accessed via \url{http://corpora.linguistik.uni-erlangen.de/demos/cgi-bin/Web1T5/Web1T5_freq.perl}
], and weight it with a free parameter $\beta$: $P(c) \propto \exp{(\beta \cdot \log \hat{f})}$
In our data analysis, we put a uniform prior over likely values of $\beta \sim \text{Uniform}(0, 3)$. 
\mht{Should I include the scraped frequencies in the report? or as a supplement on Rpubs?}

\mht{Insert plate diagram here}

### Inferring priors on degrees

$P(x \mid c)$ describes the plausible values of a degree (e.g., temperature) $x$ given a comparison class $c$ (e.g., days in Winter).
Rather than measuring these distribution by asking participants to estimate them, we will put uncertainty over their parameters and infer them from participants' responses to our questions from the two expeirments.
With simplicity, we assume each $P(x \mid c)$ is a Gaussian distribution. 
We fix each superordinate distribution $P(x \mid c^{super})$ to be a Unit-Normal and put uncertainty over the parameters of each subordinate Gaussian. 
Since each domain is using standardized units (given by the superordinate Unit-Normal), we can put the same priors over the parameters of each subordinate Gaussian: $\mu \sim \text{Uniform}(-3, 3)$, $\sigma \sim \text{Uniform}(0, 3)$.
These $P(x \mid c)$ are used in both the experiments, which allows us to both simultaneously gain credibility in our estimates of these parameters as well as in our model, which has to predict data from two distinct experiments.

The model also has two parameters not of direct theoretical interest: the speaker optimality parameters $\alpha^\text{expt}_{i}$.
Experiment 1 uses the pragmatic listener $L_1$ model, which has one speaker optimality: $\alpha^\text{1}_{1}$.
Experiment 2 uses the pragmatic speaker $S_2$ model, which has two speaker optimality parameters: 
$\{\alpha^\text{2}_{1}, \alpha^\text{2}_{2}\}$
We put the following priors over these parameters: $\alpha_1 \sim \text{Uniform}(0, 20)$, $\alpha_2 \sim \text{Uniform}(0, 5)$

## Results

We implemented the RSA model and the Bayesian data analysis model in the probabilistic programming language WebPPL [@dippl].
To learn about the credible values of the parameters and the predictions, we used an incrementalized version of MCMC [@Ritchie2016], collecting 4 independent chains of 30,000 iterations (removing the first 10,000 for burn-in).

```{r}
# n_chains  = 3
# n_samples = 15000
# m.samp <- data.frame()
# 
# # expt 1 & 2, L1 model with only explicit and silence alternatives (no pos / neg) (1/26)
# file.prefix <- "fbt-L1-explAlt-empiricalCC-disc3-mcmc15000_burn7500_chain"
# 
# for (i in seq(1, n_chains)){
#   m <- as.data.frame(fread(paste(project.path,"models/sherlock/results/",
#                                  file.prefix, i, ".csv", sep="")))
#   m.samp.i <- rwebppl::get_samples(m, n_samples)
#   m.samp <- bind_rows(m.samp, m.samp.i)
# }
load(paste(
   project.path,
   "writing/cogsci17/model_results/fbt-L1-explAlt-empiricalCC-disc3-mcmc15000_burn7500_3chain.RData",
   sep = ""))
m.samp.tidy <-left_join(
  m.samp %>% filter(param == "prior"),
  d %>% select(degree, sub_category, strength) %>% unique() %>%
  rename(cat = sub_category)
) %>% 
  mutate(strength = factor(strength, levels = c(1,2,3),
                           labels = c("low","medium","high")))

# save(m.samp, file = 
#        paste(
#          project.path, 
#          "writing/cogsci17/model_results/fbt-L1-explAlt-empiricalCC-disc3-mcmc15000_burn7500_3chain.RData", 
#          sep = ""))
```
```{r priorsFig, fig.env = "figure*", fig.pos = "htb", fig.width=6.6, fig.height=2, fig.align='center', set.cap.width=T, num.cols.cap=2, fig.cap = "Inferred world knowledge used in Experiments 1 and 2."}

ggplot(m.samp.tidy, aes(x = val, y = ..scaled.., 
                 fill = strength, lty = strength))+
  geom_density(adjust = 2, size = 0.8, alpha = 0.8)+
  scale_fill_manual(values = c("#edf8b1","#7fcdbb","#2c7fb8"))+
  #scale_color_manual(values = c("#edf8b1","#7fcdbb","#2c7fb8"))+
  facet_wrap(~degree, scales = 'fixed', nrow = 1)+
  xlim(-3, 3)+
  theme(strip.text.y = element_text(angle = 0),
        legend.position = "bottom", legend.direction = "horizontal") +
  xlab("Degree value")+
  ylab("Inferred prior probability")
```

```{r parameterPosteriors}
m.so <- m.samp %>% filter(cat %in% c("speakerOptimality_s1", "speakerOptimality_s2")) %>%
  separate(cat, into = c("cat", "speaker"))  %>%
  group_by(cat, param, speaker) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = HPDhi(val),
            cred_lower = HPDlo(val))

m.freq <- m.samp %>% filter(cat %in% c("silenceCost","explicitCost","superCatPrior", "beta")) %>%
  group_by(cat) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = HPDhi(val),
            cred_lower = HPDlo(val))

a1.1 <- filter(m.so, param == "ccRSA" && speaker == "s1")
a1.2 <- filter(m.so, param == "superSpeaker" && speaker == "s1")
a2.2 <- filter(m.so, param == "superSpeaker" && speaker == "s2")
```

Maximum a-posteriori (MAP) estimate and 95\% highest probability density (HPD) interval for model parameters specific to the $L_1$ model used for Experiment 1: 
$\alpha^{1}_{1} = `r round(a1.1[["MAP"]],2)` [`r round(a1.1[["cred_lower"]],2)`, `r round(a1.1[["cred_upper"]],2)`]; \beta = `r round(m.freq[["MAP"]],2)` [`r round(m.freq[["cred_lower"]],2)`, `r round(m.freq[["cred_upper"]],2)`]$ 

Model parameters specific to the $S_2$ model used for Experiment 2: 
$\alpha^{2}_{1} = `r round(a1.2[["MAP"]],2)` [`r round(a1.2[["cred_lower"]],2)`, `r round(a1.2[["cred_upper"]],2)`]; \alpha^{2}_{2} = `r round(a2.2[["MAP"]],2)` [`r round(a2.2[["cred_lower"]],2)`, `r round(a2.2[["cred_upper"]],2)`]$



# Discussion

\begin{enumerate}
\item Speaker knowledge: If you're a basketball scout, and you say of a player that "He is tall." it means "Tall relative to basketball players"
\item QUD: If we're deciding what to do on Friday night, you say "The opera is expensive" it means "Expensive relative to other things we could do on Friday night"
\item Hyperbole / *normative* comparison classs: If we listen to a lecture, and you say "That *was long*.", it means "Long relative to how long I think it should have been." If we go out for pasta, and you ask how it was, and I say "it was expensive" it means "expensive relative to how much it should have been given the quality".
\item Item heterogeneity: Movies is not a subordinate to "things you watch online", but the model still works
\item Comparison class prior: There is an interpretation as a noisy-channel model where the semantics of *tall* requires a comparison class, and the listener has to repair the utterance via the comparison class prior. Another (non mutually exlcusive) interpretation is more cognitive that surrounds the heterogeneity of the group w.r.t. dimension.  Basic level effects are also probably here, and correlated with the frequency and length measurements we took. 
\end{enumerate}

\red{TO DO}
\begin{enumerate}
\item Settle on alternative utterances for the final model. (Run full model, then do simulations with inferred parameters)
\item More model exploration with simulations on the variability vs mean
\end{enumerate}





# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in}
\setlength{\leftskip}{0.125in}
\noindent


<!--
# Outline

1. We introduce an extension to RSA that does inference over what is the comparison class.

2. We take a simple case, where the comparison class is either a sub- or super-ordinate category. Just playing with the parameters off the model, we see this predicted (qualitative) interaction:

- When the subclass has a high mean relative to the superclass, positive form adjectives signal the superclass, and negative form signals the subclass

- When the subclass has a low mean relative to the superclass, positive form adjectives signal the subclass, and negative form signals the superclass

3. We test this predictions on 5 scales (Expt. 1)

- We see the qualitative effect on all 5 scales, but there is considerable heterogeneity among the scales.

4. This heterogeneity might be attributed to differences in the quantitative details (i.e., the parameters) of the subclass vis-a-vis the superclass

- We can perform BDA to see if this is true, but this model is actually overparameterized.

- We can simplify by assuming each superclass has a unit-normal prior, and infer the mean and standard deviation for each subclass prior.

- That’s 2 parameters for each subclass, and we only have 2 items for each subclass (namely, positive and negative form adjectives e.g., “tall” and “short” bball players)

5. We estimate the prior parameters by asking other questions of our model that should (a) access the same priors; and (b) not add other parameters

so we can ask a vague speaker question (Expt 2. [VPE])

This will alleviate the overparameterization problem and is, in general, a new way of testing language understanding models without having to explicitly measure priors
-->
