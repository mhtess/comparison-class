// webppl fbt-L1_L0theta-S1-corpusCC-noExplicitUtts-imh.wppl --require utils --require ~/tools/webppl-sample-writer-fork by_item by_item 1

// global or by_item
var comparison_class_prior_intercept = process.argv[process.argv.length - 3]
var comparison_class_prior_slope = process.argv[process.argv.length - 2]

var flat_cc_parameters = (comparison_class_prior_intercept == "flat" && comparison_class_prior_slope == "flat")
var by_item_cc_parameters = (comparison_class_prior_intercept == "by_item" && comparison_class_prior_slope == "by_item") ? "intercept_slope" :
	(comparison_class_prior_intercept == "by_item") ? "intercept" :
	(comparison_class_prior_slope == "by_item") ? "slope" :
	"flat"

display(comparison_class_prior_intercept)
display(comparison_class_prior_slope)
display(flat_cc_parameters)
display(by_item_cc_parameters)

// var utterances = ["positiveAdjective", "negativeAdjective", "silence"]
var utterances = ["positiveAdjective", "negativeAdjective"]

var chain = last(process.argv) // load index as last command line index

var meaning = function(utterance, state, threshold) {
  utterance == "positiveAdjective" ? state > threshold :
  utterance == "negativeAdjective" ? state < threshold :
  true
}

var round = function(x){
  return Math.round(x*10)/10
};

var binParam = 3;
var superordinate_parameters = {mu: 0, sigma: 1}
var stateVals = map(
  round,
  _.range(superordinate_parameters.mu - 3 * superordinate_parameters.sigma,
          superordinate_parameters.mu + 3 * superordinate_parameters.sigma,
          superordinate_parameters.sigma/binParam)
);

var thresholdBins = {
	positive: map(function(x){
		return  x - (1/(binParam*2));
	}, sort(stateVals)),
	negative: map(function(x){
		return  x + (1/(binParam*2));
	}, sort(stateVals))
};

var thresholdPrior = cache(function(form){
	return Infer({
		model: function() { return uniformDraw(thresholdBins[form]) }
	});
});


var dataPath = "../../data/";
// var dataPath = "/home/mtessler/projects/comparison-class/data/"
// var cc_inference_DataFile = "pilot-classElicitation-free-4/class-elicitation-free-4-cleaned-data-w-sub2.csv";
// var cc_inference_DataFile = "pilot-classElicitation-free-4/class-elicitation-free-4-cleaned-data-w-sub-pl.csv";
// var cc_inference_DataFile = "class-elicitation-prereg-final/auto-classified-data-w-freqs-final.csv";
var cc_inference_DataFile = "class-elicitation-prereg-final/full-classified-data-w-produced-super.csv";

// var adj_endorse_DataFile = "pilot-adj-endorsement-1/pilot-adj-endorsement-1-super-SG-subset.csv";
// var adj_endorse_DataFile = "pilot-adj-endorsement-1/pilot-adj-endorsement-1-super-PL.csv";
var adj_endorse_DataFile = "adjective-endorsement-prereg-final/adjective-endorsement-prereg-trials-w-freqs.csv"
// var corpus_frequency_DataFile = "webgram-freqs-unique-nps.csv";

// var ccData = dataFrame(csv.read(dataPath + cc_inference_DataFile), ["specific"])
// var vsData = dataFrame(csv.read(dataPath + adj_endorse_DataFile), ["val"])
// var corpus_frequency_data =  dataFrame(csv.read(dataPath + corpus_frequency_DataFile), ["Frequencies"])
var ccData = readDataFile(dataPath + cc_inference_DataFile,  ["stim_id", "specific", "subFreq", "superFreq"])
var vsData = readDataFile(dataPath + adj_endorse_DataFile, ["stim_id", "val",  "subFreq", "superFreq"])
// var corpus_frequency_data = readDataFile(dataPath + corpus_frequency_DataFile, ["Frequencies"])

var logistic = function(x) {1 / (1 + Math.exp(-x))}

var degrees = levels(vsData, "degree");
var stim_ids = sort(levels(ccData, "stim_id"));
// display(stim_ids)
// var degrees = degrees0.slice(0, degrees0.length - 1);

var model = function(){

  // separate speakerOptimality for each task
  var alphas = {
    adj_endorse: uniformDrift( { a:0, b: 20, width: 2} ),
    cc_inference: uniformDrift( { a:0, b: 20, width: 2} )
  }

  // var silenceCost = uniformDrift({a: 0, b: 10, width : 0.5})
  // var utteranceProbs = [1, 1, silenceCost];
	var utteranceProbs = [1, 1];
  // var utteranceProbs = map(function(c) {return exp(-c)}, utteranceCosts);
  var UtterancePrior = Categorical({ vs: utterances, ps: utteranceProbs })

	var interceptEffect = comparison_class_prior_intercept == "flat" ? 0 : gaussianDrift({mu:0, sigma: 2, width: 0.5})
	var frequencyEffect = comparison_class_prior_slope == "flat" ? 0 : uniformDrift({a: -3, b: 3, width: 0.5})

	var dummyClassParameters = {
		class_type_1: {
			intercept: interceptEffect,
			frequency: frequencyEffect
		},
		class_type_2: {
			intercept: comparison_class_prior_intercept == "by_item" ? gaussianDrift({mu: 0, sigma: 2, width: 0.5}) : interceptEffect,
			frequency: comparison_class_prior_slope == "by_item" ? uniformDrift({a: -3, b: 3, width: 0.5}) : frequencyEffect
		}
	}

	// could be made smarter by not conditioning the prior on class_type_2 on the sampled value of class_type_1?
	var comparison_class_subordinate_prior_prob = {
		class_type_1: logistic(dummyClassParameters.class_type_1.intercept),
		class_type_2: logistic(dummyClassParameters.class_type_2.intercept)
	}

	var classParameters = {
			basic_super : (
				comparison_class_subordinate_prior_prob.class_type_1 >
				comparison_class_subordinate_prior_prob.class_type_2
			) ? dummyClassParameters.class_type_1 : dummyClassParameters.class_type_2,
			sub_basic : (
				comparison_class_subordinate_prior_prob.class_type_1 >
				comparison_class_subordinate_prior_prob.class_type_2
			) ? dummyClassParameters.class_type_2 : dummyClassParameters.class_type_1,
	}

	// what we assume about the comparison class priors
	// there is a basic-level bias, where the basic level will be preferred
	// -- this means that the prior will be > 0.5 for one item_type and < 0.5 for the other_item type
	// -- we code the higher of the two prior intercepts as the basic_super and the lower as sub_basic
	// (we don't know which items are sub-basic and which ones are basic-super)

	// we could also assume just positive vs. negative slope for the two kinds (no diff. intercept)

	// CHANGE TO looping over stim_id?
	foreach(stim_ids, function(stim_id){
		// foreach(degrees, function(degree){
			// display(degree)

			var data_within_stim_id_cc = _.filter(ccData, {stim_id: stim_id});
			var data_within_stim_id_adj = _.filter(vsData, {stim_id: stim_id});
			// var superordinate_categories = levels(data_within_degree_cc, "superordinate_pl")
			var subordinate_categories = levels(data_within_stim_id_cc, "NP_sg");

			// display(superordinate_categories)

			data_within_stim_id_cc.length == 0 ? display("====EMPTY stim_id ADJ====" + stim_id + "_") : null
			data_within_stim_id_adj.length == 0 ? display("====EMPTY stim_id CC====" + stim_id + "_") : null

    // foreach(superordinate_categories, function(superordinate){
			// display(superordinate)
			// var sup = superordinate == "floors" ? "floor materials" : superordinate
      // var data_within_superordinate_cc = _.filter(data_within_degree_cc, {superordinate_pl: superordinate});
			// var data_within_superordinate_adj = _.filter(data_within_degree_adj, {superordinate_pl: superordinate});
			// display(subordinate_categories)


			// var supercatWeight = exp(
			// 	classParameters.frequency *
			// 	Math.log(data_within_superordinate_cc[0].superFreq)
			// );

      foreach(subordinate_categories, function(subordinate){

				var item_set_heirarchy =  flat_cc_parameters ?
					"sub_basic" :
					categorical({ps: [0.5, 0.5], vs: ["sub_basic", "basic_super"]})

				// display(subordinate)
        var subordinate_parameters = {
          mu: uniformDrift({a: -3, b: 3, width: 0.5}),
          sigma: uniformDrift({a: 0, b: 3, width: 0.3})
        };

        var data_within_subordinate_cc = _.filter(data_within_stim_id_cc, {NP_sg: subordinate});
				var data_within_subordinate_adj = _.filter(data_within_stim_id_adj, {NP_sg: subordinate});

				data_within_subordinate_cc.length == 0 ? display("====EMPTY SUB ADJ====" + stim_id + "_" + subordinate) : null
				data_within_subordinate_adj.length == 0 ? display("====EMPTY SUB CC====" + stim_id + "_" + subordinate) : null

        var subcatWeight = logistic(
					classParameters[item_set_heirarchy].intercept +
					classParameters[item_set_heirarchy].frequency * Math.log(
						data_within_subordinate_cc[0].subFreq / data_within_subordinate_cc[0].superFreq
					)
				)

				// var subcatWeight = uniformDrift({a:0, b:1, width: 0.1})
				var supercatWeight = 1 - subcatWeight

        var comparisonClass_prior = Categorical({
					vs: ["superordinate", "subordinate"],
					ps: [supercatWeight, subcatWeight]
				})

				// displayObj(subordinate_parameters)
				// displayObj(superordinate_parameters)
				// displayObj(stateVals)
        var stateProbs = {
          subordinate: map(function(s){
            Math.exp(Gaussian(subordinate_parameters).score(s))+
            Number.EPSILON
          }, stateVals),
          superordinate: map(function(s){
            Math.exp(Gaussian(superordinate_parameters).score(s))+
            Number.EPSILON
          }, stateVals)
        };
				// displayObj(stateProbs)
        var statePrior = {
          subordinate: Categorical({ vs:stateVals, ps:stateProbs.subordinate}),
          superordinate: Categorical({ vs:stateVals, ps:stateProbs.superordinate})
        };

      var literalListener = cache(function(utterance, comparisonClass) {
				var form = utterance.split('Adjective')[0]
				// display(form)
        Infer({model: function(){
          var state = sample(statePrior[comparisonClass]);
          var threshold = form == "silence" ? "NA" : sample(thresholdPrior(form));
          var m = meaning(utterance, state, threshold);
          condition(m);
          return state;
        }})
      }, 10000);

			/////////////////////////////////////////////////
      // for Comparison Class Inference task
      var speaker1 = cache(function(state, comparisonClass, form) {
        Infer({model: function(){
          var utterance = sample(UtterancePrior)
          var L0 = literalListener(utterance, comparisonClass)
          factor( alphas.cc_inference * L0.score(state) )
          return utterance
        }})
      }, 10000)

      var pragmaticListener = function(form) {
        var utterance = form + "Adjective";
        Infer({model: function(){
          var comparisonClass = sample(comparisonClass_prior);
          var state = sample(statePrior.subordinate);
          var S1 = speaker1(state, comparisonClass, form);
          observe(S1, utterance);
          return comparisonClass == "subordinate" ? 1 : 0
        }})
      }
			/////////////////////////////////////////////////

      /////////////////////////////////////////////////
      // for Adjective Endorsement task
      var speaker1_super = cache(function(form) {
        Infer({model: function(){
          var utterance = uniformDraw([form + "Adjective", "silence"])
          var speakerBeliefs = statePrior.subordinate;
          var L0 = literalListener(utterance, "superordinate")

          var _kl = KL(speakerBeliefs, L0, speakerBeliefs.support());
          factor(-1 * alphas.adj_endorse * _kl)

          return utterance == (form + "Adjective") ? 1 : 0
        }})
      }, 10000)
      ////////////////////////////////////////

      foreach(["positive","negative"], function(adj_polarity){

        var d_subcat_superSpeaker = _.map(
          _.filter(data_within_subordinate_adj, {adj_polarity}),
        "val");

        var d_subcat_ccInference = _.map(
            _.filter(data_within_subordinate_cc, {adj_polarity}),
        "specific");

        var superSpeakerProbs = speaker1_super(adj_polarity);

				d_subcat_superSpeaker.length == 0 ? display("====EMPTY form ADJ====" + stim_id + "_" + subordinate + "_" + adj_polarity) : null
				d_subcat_ccInference.length == 0 ? display("====EMPTY form CC====" + stim_id + "_" + subordinate+ "_" + adj_polarity) : null

        mapData({data:d_subcat_superSpeaker}, function(d){
	         // console.log("superSpeaker = " + superSpeakerProbs.score(d))
          observe(superSpeakerProbs, d)
        })

        var ccRSA = pragmaticListener(adj_polarity);

        mapData({data:d_subcat_ccInference}, function(d){
         // console.log("cc = "+ ccRSA.score(d))
          observe(ccRSA, d);
        })

        query.add(["stim_"+stim_id, subordinate,  "adjEndorse", adj_polarity], Math.exp(superSpeakerProbs.score(1)))
        query.add(["stim_"+stim_id, subordinate, "subordinateCC", adj_polarity], Math.exp(ccRSA.score(1)))

      })

      query.add(["stim_"+stim_id, subordinate, "mu", "NA"], subordinate_parameters.mu);
      query.add(["stim_"+stim_id, subordinate, "sigma", "NA"], subordinate_parameters.sigma);
			query.add(["stim_"+stim_id, subordinate, "classPrior_sub", "NA"], subcatWeight);

			if (!flat_cc_parameters) {
				query.add(["stim_"+stim_id, "NA", "item_heirarchy_sub_basic", by_item_cc_parameters], item_set_heirarchy == "sub_basic" ? 1 : 0)
			}

    })

  })

	// if (!flat_cc_parameters) {
	// 	query.add(["beta", "frequency",  "sub_basic", "global"], frequencyEffect)
	// 	query.add(["beta", "intercept",  "sub_basic", "global"], interceptEffect)
	// } else {
	if (!flat_cc_parameters) {
		query.add(["beta", "frequency",  "basic_super", by_item_cc_parameters], classParameters.basic_super.frequency)
		query.add(["beta", "intercept",  "basic_super", by_item_cc_parameters], classParameters.basic_super.intercept)
		query.add(["beta", "frequency",  "sub_basic", by_item_cc_parameters], classParameters.sub_basic.frequency)
		query.add(["beta", "intercept",  "sub_basic", by_item_cc_parameters], classParameters.sub_basic.intercept)
	}

	// query.add(["parameter", "silenceProb", "NA",  "NA", by_item_cc_parameters], silenceCost)
  query.add(["speakerOptimality","adjEndorse", "NA", by_item_cc_parameters], alphas.adj_endorse)
  query.add(["speakerOptimality","subordinateCC", "NA", by_item_cc_parameters], alphas.cc_inference)

  // return _.object(_.flatten(parameters, true));
  return query
}

// var totalIterations = 100, lag =  1;
// var totalIterations = 250000, lag =  25;
// var totalIterations = 150000, lag =  50;
var totalIterations = 300000, lag =  150;
// var totalIterations = 5000, lag = 2
var samples = totalIterations/lag, burn = totalIterations / 2;
var outfile = 'results-L1-S1-fullClassified-sansSilence-corpusFreqCCLogistic_byNP_'+by_item_cc_parameters+'-mcmc-'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'

var header = "iteration,stim_id,subordinate,task,adj_polarity,val,score"
var callback = webpplSampleWriter.streamQueryCSV("results/" + outfile, header);

Infer({model,
      samples: samples, burn: burn, lag: lag == 1 ? 0 : lag,
       method: 'incrementalMH',
       onlyMAP: true,
       verbose: T,
       verboseLag: totalIterations / 20,
       callbacks: [callback]});

 "written to " + outfile;
